<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>科研入门指南</title>
    <link href="/2023/11/06/2023-08-24-%E7%A7%91%E7%A0%94%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/"/>
    <url>/2023/11/06/2023-08-24-%E7%A7%91%E7%A0%94%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>整理研究生入门科研中可能用到的一些内容。里面包含了师兄的建议和部分研究生自立更生完成课题的内容，若老师详细指导则酌情参考。</p><span id="more"></span><h1 id="常用网址">常用网址</h1><ul><li>数学和机器学习基础<ul><li><a href="https://github.com/ML-NLPChina/MIT-Linear-Algebra-Notes">MIT</a><a href="https://github.com/ML-NLPChina/MIT-Linear-Algebra-Notes">线代笔记</a></li><li><a href="https://github.com/yhangf/ML-NOTE">机器学习笔记</a></li><li><a href="https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497">李沐</a><a href="https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497">-</a><a href="https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497">动手学深度学习</a></li></ul></li><li>会议deadline<ul><li>https://ccfddl.github.io/</li><li>https://www.myhuiban.com/</li></ul></li><li>NLP任务领域SOTA<ul><li>https://paperswithcode.com/sota</li><li>https://nlpprogress.com/</li><li>https://www.jiqizhixin.com/sota</li></ul></li><li>数据集收集<ul><li>https://datasetsearch.research.google.com/</li><li>https://paperswithcode.com/datasets</li><li>https://github.com/awesomedata/awesome-public-datasets</li><li>https://www.cluebenchmarks.com/dataSet_search.html</li></ul></li></ul><h1 id="常用软件">常用软件</h1><p>Mendeley Desktop：本地化，分类构建个人图书馆</p><p>ReaderPaper：在线读论文，查论文，上传论文，构建在线图书馆</p><p>翻译软件：Google或大模型翻译器</p><p>科研语法检错：Grammarly，商业化GPT</p><h1 id="数据集">数据集</h1><h2 id="数据集收集方法">数据集收集方法</h2><ul><li>读论文顺便收集</li><li>Benchmark打榜数据集</li><li>顶会论文发表的数据集（最新数据集）</li><li>课题组发论文常用数据集</li><li>Hugging Face、Github、Kaggle、数据集开源网站等</li></ul><h1 id="文献检索">文献检索</h1><h2 id="重要性">重要性</h2><p>文献检索重要性不言而喻，需要从<strong>准确性、效率和全面性</strong>三方面不断提高。文献检索要追踪热点，找容易上手的课题（文献多的方向）。</p><h2 id="常用方法">常用方法</h2><h3 id="方法1从关键词入手">方法1：从关键词入手</h3><p>研究对象+方法（问题），至少2个关键词</p><h3 id="方法2以核心文献引用入手">方法2：以核心文献引用入手</h3><p>从导师给的文献入手，看这篇文献的引用，哪些文献引用了这一篇，再把方法扩展到相关文献。</p><p>尽量采用方法1囊括所有文献，在方法1不好用时用方法2扩展，至少30篇高质量论文。</p><h3 id="跟踪技术前沿">跟踪技术前沿：</h3><ul><li>Arxiv.org前沿投递</li><li>知乎</li><li>顶会、顶刊（入门可借鉴tutorial，workshop进行方向性思考，进阶看long paper）</li></ul><h2 id="常用工具">常用工具</h2><ul><li>官方：<ul><li>CNKI</li><li>万方</li><li>web of science</li></ul></li><li>非官方：<ul><li>文献部落（http://459.org/)</li></ul></li></ul><h2 id="注意事项">注意事项</h2><ol type="1"><li>进行英文检索需要穷尽所有同义词</li><li>正确使用“与”和“或”</li><li>只读好论文，学会使用检索排除差论文</li><li>先看优秀硕博论文，了解基本后读英文文献，慢慢上难度。</li></ol><h1 id="文献阅读">文献阅读</h1><h2 id="四类阅读">四类阅读</h2><h3 id="选读-关键词阅读法">选读-关键词阅读法</h3><p>筛选30篇（最少10篇），只阅读关键词段落，采用对比阅读快速理解核心概念。</p><p>目的：了解该领域工作，判断自身想法是否靠谱。</p><h3 id="粗读-论文框架阅读">粗读-论文框架阅读</h3><p>聚焦5-10篇核心论文，采用框架阅读法做读书笔记，进行课题设计</p><p>目的：找切入点</p><h3 id="精读-方法或实验重现">精读-方法或实验重现</h3><p>聚焦1篇核心论文，其他论文都是为帮助理解或复现该论文</p><p>目的：方法是怎么实现的，结果是怎么算出来的，对着方法介绍和实验来看</p><h3 id="细读-论文写作">细读-论文写作</h3><p>聚焦1-3篇最相似的论文，模仿其谋篇布局、段落组织</p><p>目的：写作套路，语句及段落要复述</p><h2 id="有效阅读文献">有效阅读文献</h2><ol type="1"><li><p>5-20篇能够对一个领域基本了解，50-100篇（不一定全要精读）可以写论文，表达观点。</p></li><li><p>每周读5-6篇文献，读懂2-3篇，挑出1-2篇进行讨论，不断更新认知。</p></li><li><p>重要文献应反复阅读，在精力最充沛的时候读。</p></li><li><p>文献内容重要性排序应是为什么（研究目的与意义）到怎么做（研究方法的创新）再到做什么（具体实现步骤与结果），按顺序回答三个问题。回答完后立刻问自己：该文献对我是否有用？<strong>切忌只读不思考</strong>。</p></li></ol><h1 id="论文写作">论文写作</h1><h2 id="素材库整理">素材库整理</h2><p>素材库建立步骤：</p><ol type="1"><li>找5-10篇需要精读的相关论文，不易太多</li><li>对每篇论文逐句进行信息分类做标签，提炼关键字。标签包括是什么，为什么，怎么做，对象，目的，意义等。</li><li>对分类信息进行归类，完成素材库整理。</li></ol><h2 id="如何提高论文写作速度">如何提高论文写作速度</h2><ol type="1"><li>技巧方面：<ol type="1"><li>思维技巧：将注意力集中在：<ol type="1"><li>论文到底想表述什么观点（不断审视，反思所提出观点贡献，创新在哪）</li><li>绘制图标、整理数据、撰写文字时如何让观点更清晰、直接。</li></ol></li><li>素材整理。论文写作中边写边读文献，不断整理素材，提升对问题的认知。</li></ol></li><li>心态方面：<ol type="1"><li>戒骄戒躁。对初学者做好一篇小论文半年甚至一年都比较正常。</li><li>耐心耐烦。<strong>论文写作本质是重复修改</strong>，非常耗时、耗力的过程。</li><li>不抱怨，降低对导师的期待。论文写好是自己的事情，导师是引导和指导。反思自己一天花了多少时间是认真写论文，有没有用心思考，用心提升自己，为自己行为负责。</li></ol></li></ol><h2 id="如何写好文献综述">如何写好文献综述</h2><p>首先不建议硕士研究生专门写文献综述小论文。该部分主要作为毕业论文的第一部分绪论。毕业论文的重要部分是三四部分即独立完善的小论文构成的创新点1、2。所以毕业论文的写作顺序为先写三四部分（小论文），再写第一部分（文献综述）。</p><p>文献综述的目的：针对某一研究问题，通过对当前文献进行分类、对比、分析，找到国王研究不足并为将来研究提供建议。</p><p>写作方法1-对比法：从4个切入点，对已有研究进行归纳并对比：</p><ol type="1"><li>方法</li><li>案例（研究对象）</li><li>影响变量（参数）</li><li>评价指标</li></ol><p>写作方法2-过程描述法：文献检索过程描述：关键词确定，找到了几篇论文。把找论文这个事情的过程进行描述如下图所示，然后进行趋势分析。</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202309031553638.png" alt="image-20230903155342373" style="zoom: 67%;" /></p><h2 id="论文写作注意事项">论文写作注意事项</h2><p>文献数量，引用原则及分布：</p><ol type="1"><li>EI、中文核心一般引用论文为10-15篇；SCI一般20-30及以上。引文数量不是绝对的，但太少表明对该研究问题了解不够深入，认识不够全面。很多审稿人会根据引用文献数量和质量评价论文是否录用。</li><li>引用原则：应用投稿期刊的最近2年相关论文（更换投稿期刊时更换引用论文）；引用潜在审稿人的论文（可引用熟人）；引用本领域高质量SCI期刊最近2年相关论文以及经典高被引文献；不要引用质量很差期刊的论文、学位论文、老旧文献。</li><li>引文分布：EI、核心论文需对1-3篇论文（SCI论文3-5篇）进行专门评论并明确指出不足，以阐释动机。</li></ol><h1 id="课题设计思路">课题设计思路</h1><h2 id="科研论文的特点">科研论文的特点</h2><ol type="1"><li>科研论文要有<strong>创新</strong>，即提出新的观点、给出新的知识。</li><li>什么是创新：与别人的研究有差异性（不同）并且该差异性使问题能被更好的解决或被更好的理解。</li></ol><p>总之，创新的本质就是对比，就是找差异。</p><h2 id="如何制造创新点">如何制造创新点</h2><p>四个方面：</p><ol type="1"><li>研究案例/研究对象</li><li>研究方法</li><li>影响因素/变量</li><li>评价指标</li></ol><p>关系如下图所示：</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202308241522522.png" alt="image-20230824152231973" style="zoom:67%;" /></p><p>决定论文价值的是实验结果与已有结果的差异，以及差异贡献的大小，不是工作量。要在尽量少的工作中给出足够的创新点。</p><p>创新点：你的研究与别人研究的差异（不同之处），且该差异使得问题被更好的解决或理解。</p><p>总之创新点的提炼是通过对比找差异，并论证该差异能够使得问题被更好的解决或提供新的知识。</p><p>注意，创新点不需要惊天地泣鬼神，一点点改进或者新的认知即可。</p><p>创新点提炼：</p><ol type="1"><li>提出新问题</li><li>研究案例更大更特殊</li><li>研究方法不同或对比分析不同方法性能的差异</li><li>分析影响因素、变量对研究方法或案例的影响</li><li>提出新的指标</li></ol><h2 id="如何选课题">如何选课题</h2><p>从研究难度和研究意义来看。硕士建议研究意义和难度都小的课题。</p><p>选择课题时注意：</p><ol type="1"><li>选老师擅长和关心的领域，课题组有成果的</li><li>选题要小，聚焦、具体，“小口大肚”且有大量参考文献的课题，牢记能做什么大于想做什么，别选没有参考文献的。</li><li>要及时产生正面反馈，如一般3-5月能发出论文</li></ol><p>选题的两个方法：</p><ol type="1"><li>通过期刊。找本领域主流期刊（中科院一二区影响因子高的欧美期刊），看看期刊近两年在哪个方向上论文最多。</li><li>通过大佬。找行业内大佬，看他们最近发表的论文。大佬包括主流期刊副主编或在该刊上发表20+；在一个领域深耕20年的欧美学者；他人引用1000+；近3年连续发文者。</li></ol><p>选题3个原则：</p><ol type="1"><li>封闭原则：近30年有至少30篇以上的相关文献，但该问题没有被很好的解决（未工业化），仍有改进空间。即你知道要解决什么问题且解决起来有一定困难</li><li>可获得原则：研究对象资料能够通过文献或其他途径获得</li><li>容易上手、替代原则：研究方法容易学，且能够找到替换方法</li></ol><p>三个阶段：</p><ol type="1"><li>初期阶段：根据选题两个方法用关键字检索，找到30篇相关SCI论文进行泛读。（2-3个月，结合硕博论文了解基本概念，难度慢慢上）</li><li>中期阶段：根据选题3个原则，找一篇最新、高质量的SCI论文，花半年到一年时间，把该论文复现。该阶段最重要也最难熬</li><li>后期阶段：在复现的基础上稍作修改可发一篇中文论文，替换方法可以发SCI二三四区</li></ol><h2 id="如何通过文献找研究课题">如何通过文献找研究课题</h2><ol type="1"><li>文献筛选，对类似文献进行归类</li><li>整理阅读笔记，从研究案例/研究对象、研究方法、影响因素/变量、评价指标四方面对比文献差异</li><li>组合创新</li></ol><h2 id="如何快速肝出高质量开题报告">如何快速肝出高质量开题报告</h2><h3 id="开题报告框架">开题报告框架</h3><h4 id="选题依据研究意义国内外研究现状和发展动态分析">1. 选题依据（研究意义，国内外研究现状和发展动态分析）</h4><p>回答为什么要做，选题的重要性与必要性，别人做了什么，有哪些不足。</p><p>1.1 题目拟定 = 方法+目的（解决问题）</p><p>从现实角度论述研究意义：解决该问题可以推动社会经济发展、提高效益；然而在解决该问题在方法上存在困难，相关问题没弄清</p><p>1.2 文献综述：国内外学者研究进展，可按照时间顺序罗列，可评述不足</p><p><strong>建议</strong>：老师不会细看，好水字数，尽量多写，找几篇相关硕士论文进行参考，5页+</p><h4 id="研究内容研究目的与解决关键问题">2. 研究内容、研究目的与解决关键问题</h4><p>回答做什么，将课题拆解为几个独立的模块，分别阐述每块采用的方法，研究目标等。</p><p>2.1 研究内容：分3-4块，每块相当于一个独立小论文，对应大论文的一章。写法就是小论文摘要的前半部分：针对xx问题或不足，采用xx方法，构建xx、开展xx、研究xx。每个 研究内容大概5句，总篇幅大概1页。写的时候每章参考一篇论文来写。</p><p>2.2 研究目的：解决问题后得到的成果与贡献，内容有几块目的就有几个，目的可以是一句话，简短一点。</p><p>2.3 解决关键问题：研究内容中的难点或阻碍的难题，一般几个研究内容就有几个关键问题。</p><p><strong>建议</strong>：老师重点阅读，2页左右，文字一定要通畅。</p><h4 id="拟采用研究方案以及可行性分析研究方法技术路线实验手段关键技术">3. 拟采用研究方案以及可行性分析（研究方法、技术路线、实验手段、关键技术）</h4><p>回答怎么做，方法具体描述，研究内容可视化。</p><p>3.1 研究方法的具体描述</p><p><strong>建议</strong>：老师不会细看，好水字数，5页左右，参考相关硕博论文。</p><p>3.2 技术路线，将研究内容用图的形式展现出来，参考相关硕博论文。</p><p><strong>建议</strong>：老师重点看，字体大小合适，构图清晰。</p><h4 id="本课题创新之处">4. 本课题创新之处</h4><p>回答有什么实际意义与理论创新。</p><p>从研究内容、研究方法、预期成果体现创新之处。</p><p><strong>建议</strong>：老师重点看，不要乱写，参考优秀硕博论文，控制篇幅半页左右，简洁凝练。</p><h4 id="研究计划与研究成果">5. 研究计划与研究成果</h4><p>按时间顺序规划研究内容并罗列研究成果。</p><p><strong>建议</strong>：老师不会细看，可以水字数，篇幅3页左右</p><p>总篇幅：5+2+5+0.5+3=15页左右。</p><h1 id="reference">Reference</h1><p><a href="https://www.bilibili.com/video/BV1bW4y1v729/">预备课1-文献检索</a></p><p><a href="https://www.bilibili.com/video/BV1YT411M7DK/">预备课2-课题设计思路</a></p><p><a href="https://www.bilibili.com/video/BV1oe4y1H7Uf/">预备课3-文献选读</a></p><p><a href="https://www.bilibili.com/video/BV1Bt4y1c7m8/">预备课4-文献阅读重要性与文献粗读方法</a></p><p><a href="https://www.bilibili.com/video/BV1QG4y1q7Yy/">预备课5—文献阅读方法论</a></p><p><a href="https://www.bilibili.com/video/BV1ve4y1p7re/">预备课5A—文献粗读—如何提高文献阅读效果</a></p><p><a href="https://www.bilibili.com/video/BV1U24y1f7LB/">预备课6—文献精读—素材库整理</a></p><p><a href="https://www.bilibili.com/video/BV1ed4y1G7ka/">预备课7—如何提高论文写作速度</a></p><p><a href="https://www.bilibili.com/video/BV14d4y1i78C/">预备课8-三天“肝出”高质量开题报告</a></p><p><a href="https://www.bilibili.com/video/BV1K24y1f7nn/">预备课9—开题报告-如何提创新点</a></p><p><a href="https://www.bilibili.com/video/BV1314y1V7Qx/">预备课10-开题避坑指南</a></p><p><a href="https://www.bilibili.com/video/BV1zV4y1T7B9/">预备课11—如何选题1</a></p><p><a href="https://www.bilibili.com/video/BV1GG4y1x7D8/">预备课12—如何选题2</a></p><p><a href="https://www.bilibili.com/video/BV1td4y1E7ka/">如何写好文献综述1</a></p><p><a href="https://www.bilibili.com/video/BV1P84y1Y7vC/">如何写好文献综述2</a></p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>科研</tag>
      
      <tag>合集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于贝叶斯主义的总结</title>
    <link href="/2023/08/06/2023-08-06-%E5%85%B3%E4%BA%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%BB%E4%B9%89%E7%9A%84%E6%80%BB%E7%BB%93/"/>
    <url>/2023/08/06/2023-08-06-%E5%85%B3%E4%BA%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%BB%E4%B9%89%E7%9A%84%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>对于文章:"真正的高手，都是贝叶斯主义者"的总结</p><span id="more"></span><p><strong>可纠错的反馈闭环</strong> 对于创业、投资、成长来说都即为重要，若与贝叶斯公式相结合，能够给出一个不确定年代尤显重要的思考和行动框架：</p><ol type="1"><li>接受不确定性，用概率思维来预测和决策；</li><li>快速行动和迭代，打造“知行一体”的反馈飞轮；</li><li>用贝叶斯公式实现“有系统”的复利效应；</li><li>重视基础概率，基于整体资产滚雪球；</li><li>对新信息保持“敏感”，又有独立判断的“钝感”；</li><li>别太完美，降低自己被证伪的概率；</li><li>成为学习机器，在适应中快速进化；</li><li>探索未知 &amp; 利用已知，在攻和守之间进行权衡；</li><li>理解贝叶斯的局限，小心应对黑天鹅事件。</li></ol><p>基于以上9个要点就能更完整地理解“可纠错的反馈闭环”。‍‍‍‍‍</p><p>贝叶斯主义是一种关于概率和统计的哲学观点，它强调信念的主观性和更新。在该观点中，贝叶斯公式是一个核心的工具，用于处理不确定性，更新信念，并指导决策。</p><p>总的来说，贝叶斯公式与很多关于知识、学习、不确定性和决策的哲学思想有关。它提供了一种强大的框架，用于理解和处理这些复杂的问题。</p><h2 id="接受不确定性用概率思维来预测和决策">1. 接受不确定性，用概率思维来预测和决策</h2><p>世界并非非黑即白，存在着许多不确定性，但我们仍然可以用概率来描述世界。<strong>对不确定性的接受和理解，是贝叶斯思维的核心。我们需要接受事物的不确定性，并利用概率来描述和理解它。</strong></p><p>贝叶斯公式提供了一个理论框架，指导我们如何根据新的数据更新我们的信念，概括而言，就是： 1. 保持开放； 2. 灰度思考； 3. 先干为敬。</p><h2 id="快速行动和迭代打造知行一体的反馈飞轮">2. 快速行动和迭代打造“知行一体”的反馈飞轮</h2><p>贝叶斯思想强调快速迭代、快速行动。只有通过实践，我们才能得到反馈，从而不断学习和进步，所谓知行合一。贝叶斯公式给出了“知行”的动力学模型。 先来看一下公式：</p><p>从数学的角度来看，贝叶斯公式是这样的：</p><p>P(H|E) = [P(E|H) * P(H)] / P(E)</p><p>其中：</p><ul><li>P(H|E) 是后验概率，即在观察到新的数据E后，假设H成立的概率；</li><li>P(E|H) 是似然度，即在假设H成立的情况下，观察到数据E的概率；</li><li>P(H) 是先验概率，即在没有观察到新的数据前，假设H成立的概率；</li><li>P(E) 是证据或边缘概率，即无论假设是否成立，观察到数据E的总概率。</li></ul><p>在人工智能中，智能体通常通过从经验中学习来变得更加“聪明”。这种学习通常涉及到对环境的观察，通过这些观察来改变智能体的行为。这种改变可能是通过改变智能体对世界的理解（即它的模型），或者是通过改变智能体决定采取什么样的行动（即它的策略）。 贝叶斯公式在这个过程中起到了关键的作用。这是因为贝叶斯公式提供了一种方法，可以将新的数据（或观察）与我们现有的信念结合起来，从而得到更新的信念。 这种更新的过程，也就是<strong>贝叶斯更新</strong>，是学习的一个关键部分。 通过贝叶斯更新，智能体可以从每一次的观察和交互中学习，不断地更新它对世界的理解。这样，智能体就可以不断地改进它的模型和策略，从而变得更加“聪明”。</p><p>贝叶斯公式描述的是一个观念更新的过程：</p><p>初始信念（先验概率）-大胆行动（获得新信息）-更新信念（后验概率）。然后，再重复如上过程。</p><h2 id="用贝叶斯公式实现有系统的复利效应">3. 用贝叶斯公式实现“有系统”的复利效应</h2><p>贝叶斯主义者，需要有自己的模型，基于一个系统，通过不断重复的连续性策略，产生复利效应。贝叶斯更新就像复利一样，将之前的学习结果积累起来，作为新一轮学习的基础。这就是所谓的"站在巨人的肩膀上"。贝叶斯思维鼓励我们积累经验，形成长期的复利效应。</p><h2 id="重视基础概率基于整体资产滚雪球">4. 重视基础概率基于整体资产滚雪球</h2><p>首先区分一下基础概率和先验概率：</p><ul><li>基础概率（Base Rate）：基础概率是关于一个类别、事件或条件的总体频率。例如，假设你想知道一个随机选中的人是否有某种罕见疾病，那么这种疾病在总体中的发病率就是基础概率。基础概率是没有任何额外信息的情况下的默认概率。</li><li>先验概率（Prior Probability）：在贝叶斯统计中，先验概率是在观察到新证据之前，我们对某一假设成立的信念。例如，你可能已经知道在一个特定的地方，人们患某种疾病的概率比总体的基础概率要高。这就形成了你对这个人是否患有这种疾病的先验概率。</li></ul><p>一般来说，当我们获得新的证据时，我们会利用贝叶斯定理更新我们的先验概率，得到后验概率。基础概率可以被看作是一种特殊的先验概率，即没有任何特定证据的先验概率。</p><p>我们做决策的时候，要眼观全局，基于整体资产来选择，并以整体资产的增长率来评判决策与行动的质量。</p><h2 id="对新信息保持敏感又有独立判断的钝感">5. 对新信息保持“敏感”又有独立判断的“钝感”</h2><p>对新信息保持“敏感”：贝叶斯公式告诉我们，当新信息（证据）到来时，我们应该更新我们的信念（概率）。这种对新信息的"敏感"表现在我们如何根据新的证据来修正我们的看法。</p><p>考虑基础概率和先验概率，保持独立判断的“钝感”：然而，我们不能盲目地只考虑新信息，还需要考虑基础概率和先验概率。这意味着我们需要结合我们的初始信念和新的证据来更新我们的看法。</p><p>我们需要学会使用数据来支持他们的决策系统，而不仅仅依赖于直觉。</p><h2 id="别太完美降低自己被证伪的概率">6. 别太完美，降低自己被证伪的概率</h2><p>当你有一个先验概率的时候，你继续获取信息，极可能会主动选择那些对你的观念（先验概率）有利的，自动屏蔽不利的。如此一来，贝叶斯公式就完全失效了。‍‍ 通过贝叶斯公式，我们可以看到证伪或否定证据的重要性。批判性思维和证伪思维是科学研究的核心，也是保持思维开放、防止陷入偏见和过度确定的重要工具。</p><p>对于高手而言，证实和证伪同样重要。只有如此，才能形成“可纠错的反馈闭环”。</p><h2 id="成为学习机器在适应中快速进化">7. 成为学习机器在适应中快速进化</h2><p>贝叶斯公式的原理和哲学与适应性和进化理性有深度的关联，它们都强调了对新信息的接收、动态更新和在不确定性中做出最优决策的重要性。 贝叶斯主义的学习机器需要有自己的系统，且可证伪、可纠错，最后每天都比之前聪明一点点。</p><h2 id="探索未知-利用已知在攻和守之间进行权衡">8. 探索未知 &amp; 利用已知，在攻和守之间进行权衡</h2><p>在贝叶斯决策过程中，需要在探索未知和利用已知之间进行权衡。我们需要持续学习、决策平衡、风险管理、灵活适应</p><h2 id="理解贝叶斯的局限小心应对黑天鹅事件">9. 理解贝叶斯的局限，小心应对黑天鹅事件</h2><p>贝叶斯推理是根据新的证据更新信念，而不是推翻旧有的信念。贝叶斯理论虽然强大且实用，但也有其局限性和缺点：</p><ol type="1"><li>依赖于先验知识</li><li>过于理想化的假设</li><li>计算复杂性高</li><li>结果可能过于保守</li></ol><p>贝叶斯公式和任何概率模型一样，有其局限性，特别是在预测罕见的“黑天鹅”事件时。以下是一些可以尝试的方法，以缓解或避免这些局限性：</p><ol type="1"><li>合理选择和更新先验概率：先验概率是贝叶斯推理的关键组成部分，一定要尽可能准确和有信息量。如果先验概率选择不当，可能会导致结果偏离实际。此外，我们必须时刻准备根据新的数据来更新我们的先验概率。</li><li>采用蒙特卡洛模拟法：蒙特卡洛模拟能够帮助我们更好地理解概率分布的全貌，包括那些罕见的事件。通过模拟大量可能的情况，我们可以获得更全面的视角，以期望在遇到“黑天鹅”时，能做出更有准备的响应。</li><li>压力测试和情景分析：尽管贝叶斯推理能够给出一个可能的结果，但我们还需要进行压力测试和情景分析，以确定我们的系统或决策是否能够抵御极端事件的影响。</li><li>注意模型的假设和局限性：任何模型都是基于某些假设的，贝叶斯模型也不例外。我们必须清楚这些假设，并了解在什么情况下，这些假设可能不再适用。当我们注意到模型可能不再适用时，我们就需要寻找其他的方法。</li><li>维持谦逊和开放的心态：面对不确定性，尤其是在面对可能会改变我们的知识或观念的新信息时，保持谦逊和开放的态度是至关重要的。我们需要理解我们的知识和理解都是有限的，永远有学习和改进的空间。</li></ol><h2 id="可纠错的反馈闭环">可纠错的反馈闭环</h2><p>可纠错的反馈闭环，对个人而言是非常重要的关键思想。所谓有算法的人生，就是以“可纠错的反馈闭环”为珍珠，串起不断更新、有复利效应的一生。</p><p>笨蛋，行动起来，不管你有多害怕。</p><h1 id="reference">Reference</h1><p><a href="https://mp.weixin.qq.com/s/r602dlcLas48ci8oG2Drig">真正的高手，都是贝叶斯主义者</a></p>]]></content>
    
    
    <categories>
      
      <category>经验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常见问题</title>
    <link href="/2023/07/19/2022-07-13-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <url>/2023/07/19/2022-07-13-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>本人在日常学习工作时遇到的常见问题及解决方法</p><span id="more"></span><h1 id="如何给pdf文件加目录">如何给PDF文件加目录</h1><p>参考:<a href="https://www.zhihu.com/question/392666875/answer/2157219298">如何给PDF文件加目录</a></p><p>文件<a href="https://link.zhihu.com/?target=https%3A//seasoning.lanzoui.com/iK4kvsm02vi">PdgCntEditor</a>已下载至本机Sumatra文件夹下, 打开即用</p><h1 id="git-hub仓库出现身份验证错误">Git Hub仓库出现身份验证错误</h1><p>错误信息:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202207131816370.png" alt="" /><figcaption>image-20220713181603979</figcaption></figure><p>出错原因:需要使用令牌访问</p><p>解决方法:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202207131816642.png" alt="" /><figcaption>image-20220713181656682</figcaption></figure><p>username为Rien190</p><p>password为GitHub之前设置的token</p><p>也可以 把<code>token</code>直接添加远程仓库链接中，这样就可以避免同一个仓库每次提交代码都要输入<code>token</code>了：</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-string">git</span> <span class="hljs-string">remote</span> <span class="hljs-built_in">set-url</span> <span class="hljs-string">origin</span> <span class="hljs-string">https</span>://&lt;<span class="hljs-string">your_token</span>&gt;@<span class="hljs-string">github</span>.<span class="hljs-string">com</span>/&lt;<span class="hljs-string">USERNAME</span>&gt;/&lt;<span class="hljs-string">REPO</span>&gt;.<span class="hljs-string">git</span><br></code></pre></td></tr></table></figure><ul><li><code>&lt;your_token&gt;</code>：换成你自己得到的<code>token</code></li><li><code>&lt;USERNAME&gt;</code>：是你自己<code>github</code>的<code>用户名</code></li><li><code>&lt;REPO&gt;</code>：是你的<code>仓库名称</code></li></ul><h1 id="电脑字体错误">电脑字体错误</h1><p>某次PC连接手机传输文件时手机文件资源管理器宕机，自动关闭后电脑字体改变。具体变化为桌面的任务图标，浏览器等应用内字体粗细和大小等发生变化。</p><p>解决方法：在windows设置-&gt;轻松使用-&gt;显示器-&gt;放大文本处先放大再缩小，重启后解决问题</p><h1 id="远程连接ssh免密码登录">远程连接SSH免密码登录</h1><p>首先在本地建立ssh key，接着在<code>git bash</code>中使用命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs git">ssh-copy-id -i ~/.ssh/xx_rsa -p port &#x27;name@host&#x27;<br></code></pre></td></tr></table></figure><p>输入服务器密码，即可在服务器上添加对应key，完成免密登录</p>]]></content>
    
    
    <categories>
      
      <category>经验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>问题集合</tag>
      
      <tag>解决方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>科研工具介绍</title>
    <link href="/2023/07/15/2023-07-15-%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7/"/>
    <url>/2023/07/15/2023-07-15-%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>记录了一些科研工具的使用以及个人配置</p><span id="more"></span><h1 id="zotero">Zotero</h1><h2 id="笔记模板">笔记模板</h2><p>使用模板, 笔记如图所示:</p><figure class="half"><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202307150112564.png"> <img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202307150112312.png"></figure><p>模板代码如下:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">h1</span>&gt;</span>$&#123;topItem.getField(&quot;title&quot;)&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">h1</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">h2</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: ##34495e;&quot;</span>&gt;</span>💡 Meta Data<span class="hljs-tag">&lt;/<span class="hljs-name">h2</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">hr</span> /&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:  #34495e&quot;</span>&gt;</span>Journal<span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:  #34495e&quot;</span>&gt;</span>Authors <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>$&#123;topItem.getCreators().map((v)=&gt;v.firstName+&quot; &quot;+v.lastName).join(&quot;; &quot;)&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: #34495e&quot;</span>&gt;</span>Date <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: #34495e&quot;</span>&gt;</span>DOI <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;https://doi.org/$&#123;topItem.getField(&#x27;DOI&#x27;)&#125;&quot;</span>&gt;</span>$&#123;topItem.getField(&#x27;DOI&#x27;)&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: #34495e&quot;</span>&gt;</span>URL <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><br><span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h1</span>&gt;</span>\n <span class="hljs-tag">&lt;<span class="hljs-name">h2</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:  ##34495e;&quot;</span>&gt;</span>📜 Main content<span class="hljs-tag">&lt;/<span class="hljs-name">h2</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">hr</span> /&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:  #34495e&quot;</span>&gt;</span>Abstract <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:  #34495e&quot;</span>&gt;</span>Motivation <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: #34495e&quot;</span>&gt;</span>Innovation <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: #34495e&quot;</span>&gt;</span>Paper Structure <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: #34495e&quot;</span>&gt;</span>Related Works <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: #34495e&quot;</span>&gt;</span>Future Works <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h1</span>&gt;</span>\n <span class="hljs-tag">&lt;<span class="hljs-name">h2</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: ##34495e;&quot;</span>&gt;</span>📌 Detail<span class="hljs-tag">&lt;/<span class="hljs-name">h2</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">hr</span> /&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h1</span>&gt;</span>\n <span class="hljs-tag">&lt;<span class="hljs-name">h2</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:##34495e;&quot;</span>&gt;</span>🔬 Reflection<span class="hljs-tag">&lt;/<span class="hljs-name">h2</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">hr</span> /&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:  #34495e&quot;</span>&gt;</span>我有什么收获 <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:  #34495e&quot;</span>&gt;</span>能否复现, 是否必要 <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:  #34495e&quot;</span>&gt;</span>是否存在作者没有处理好的细节, 有缺陷的假设, 潜在的问题 <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color:  #34495e&quot;</span>&gt;</span>文章优缺点(包括文字表述) <span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br></code></pre></td></tr></table></figure><h1 id="xshell">Xshell</h1><p>记录一些服务器常用指令:</p><p>查看当前存在哪些虚拟环境</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda <span class="hljs-built_in">env</span> list <br></code></pre></td></tr></table></figure><p>创建环境</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n your_env_name<br></code></pre></td></tr></table></figure><p>进入环境</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda activate env_name<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>科研</tag>
      
      <tag>工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于Rasa的多模态法律对话系统</title>
    <link href="/2023/03/12/2023-03-12-%E5%9F%BA%E4%BA%8ERasa%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E6%B3%95%E5%BE%8B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"/>
    <url>/2023/03/12/2023-03-12-%E5%9F%BA%E4%BA%8ERasa%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E6%B3%95%E5%BE%8B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>毕设: 基于多模态数据的法律调研与咨询对话系统的构建过程随笔</p><span id="more"></span><p>在actions/actions.py 中进行用户自定义action的编写, 参考<a href="https://ningshixian.github.io/2020/12/14/Rasa-Core-&amp;-Rasa-X-%E8%AF%A6%E8%A7%A3/">Rasa Core &amp; Rasa X 详解</a>的action部分</p><p>建议在更改数据和配置之后执行操作:<code>rasa data validate</code>, 对领域, NLU训练数据和故事进行验证。</p><h1 id="reference">Reference</h1><p><a href="https://ningshixian.github.io/2020/12/14/Rasa-Core-&amp;-Rasa-X-%E8%AF%A6%E8%A7%A3/">Rasa Core &amp; Rasa X 详解</a></p><p><a href="https://www.jianshu.com/u/4b912e917c2e">rasa对话系统踩坑系列</a></p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>多模态</tag>
      
      <tag>对话系统</tag>
      
      <tag>Rasa</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>KDD Cup 2020 大规模共享出行的分配学习赛道思路</title>
    <link href="/2022/11/12/2022-11-12-KDD%20cup2020/"/>
    <url>/2022/11/12/2022-11-12-KDD%20cup2020/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>关于个人简历中KDD Cup 2020 大规模共享出行的分配学习赛道思路</p><span id="more"></span><h1 id="赛题回顾">赛题回顾</h1><p>应用驱动的时空大数据研究</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211120834840.png" alt="image-20221112083358468" style="zoom:67%;" /></p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211120835416.png" alt="image-20221112083502558" style="zoom:67%;" /></p><p>问题的难点在于订单会随时出现，出现供需不平衡的情况；每一次决策都会影响未来全局的供需变化。</p><p>需要每一次决策都对全局的供需产生积极的影响。</p><h1 id="解决方案">解决方案</h1><p>直观的方式：分配问题（assignment problem）。但是没有考虑动态性，有较大问题。</p><p>挑战1：在线分配模型难以预知未来信息</p><p>尝试使用朴素贪心的方式。订单请求一旦出现，最近匹配查询。</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121107429.png" alt="image-20221112110704283" style="zoom:67%;" /></p><p>解决挑战1：时间窗口匹配模型。要求模型在时间窗口内必须执行一次分配，</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121109169.png" alt="image-20221112110917112" style="zoom:67%;" /></p><p>贪心方法能取得一定的结果。也有一定的提高空间</p><p>挑战2：贪心匹配策略无法捕捉供需实时变化</p><p><strong>匹配结果导致司机位置改变，从而影响供需分布。</strong></p><p>从而把匹配算法优化为序列决策问题，进而强化学习建模。</p><p>传统的，离散的优化算法（诸如ICPC）优化目标是明确的，不依赖于数据，可认为是理性主义。</p><p>机器学习需要数据驱动，因为优化目标不清楚，需要使用已知函数拟合优化目标，其中函数的一些参数确定不了，故需要调参，属于经验主义。</p><p>二者没有绝对的矛盾。</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121122315.png" alt="image-20221112112225163" style="zoom:67%;" /></p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121124042.png" alt="image-20221112112358578" style="zoom:67%;" /></p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121126260.png" alt="image-20221112112629341" style="zoom:67%;" /></p><p>二分图构造过程：</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121127746.png" alt="image-20221112112708323" style="zoom:67%;" /></p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121129540.png" alt="image-20221112112953309" style="zoom:67%;" /></p><p>组合优化匹配：</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121133916.png" alt="image-20221112113324872" style="zoom:67%;" /></p><p>价值函数更新：</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121134139.png" alt="image-20221112113401935" style="zoom:67%;" /></p><h1 id="拓展研究">拓展研究</h1><p>考虑司机公平性问题。问题的主要原因是强化学习中贪心的趋势不可控，在某一轮选择中累计了贪心的趋势，导致公平性出现问题。</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121139010.png" alt="image-20221112113941035" style="zoom:67%;" /></p><p>优化目标：面向司机收益的公平匹配</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121141823.png" alt="image-20221112114129828" style="zoom:67%;" /></p><p>冠军团队经验：</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202211121145012.png" alt="image-20221112114517325" style="zoom:67%;" /></p><h1 id="reference">Reference</h1><p><a href="https://www.zhihu.com/zvideo/1508456070464495616">北航冠军团队参赛经验分享</a></p>]]></content>
    
    
    <categories>
      
      <category>求职</category>
      
    </categories>
    
    
    <tags>
      
      <tag>简历</tag>
      
      <tag>KDD Cup</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>王博老师授课:研究生如何做科研</title>
    <link href="/2022/10/04/2022-10-4-%E5%A6%82%E4%BD%95%E5%81%9A%E7%A7%91%E7%A0%94/"/>
    <url>/2022/10/04/2022-10-4-%E5%A6%82%E4%BD%95%E5%81%9A%E7%A7%91%E7%A0%94/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>王老师研究生如何做科研视频整理</p><span id="more"></span><h1 id="什么是科学研究工作">什么是科学研究工作</h1><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202210041515772.png" alt="" /><figcaption>image-20221004151544193</figcaption></figure><h1 id="为什么做科研">为什么做科研</h1><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202210041521375.png" alt="" /><figcaption>image-20221004152110105</figcaption></figure><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202210041521886.png" alt="" /><figcaption>image-20221004152154507</figcaption></figure><h1 id="如何做科研">如何做科研</h1><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202210041525019.png" alt="" /><figcaption>image-20221004152553398</figcaption></figure><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202210041526416.png" alt="" /><figcaption>image-20221004152654103</figcaption></figure><h2 id="确定方向和问题">确定方向和问题</h2><ol type="1"><li>导师没给方向: 结合自己兴趣和当前前沿发展方向确定方向</li><li>导师给了方向没给问题: 阅读该方向近3年最新文献, 结合思考, 确定问题</li><li>导师给了方向和问题: OK</li></ol><h2 id="广泛阅读">广泛阅读</h2><h3 id="阅读哪些论文">阅读哪些论文</h3><ol type="1"><li>近3年领域顶会和刊物</li><li>上述最新论文的参考文献以及对文献的阐述</li><li>在Google scholar, Microsoft academic 等数据库中搜索高被引论文</li><li>Survey &amp; Review 或其他类型总结</li></ol><h3 id="读多少可以开始考虑研究问题">读多少可以开始考虑研究问题</h3><p>目标领域: 20-30篇精读</p><p>交叉领域: 10篇左右精读</p><h3 id="如何阅读论文">如何阅读论文</h3><ol type="1"><li>AIC(Abstract, Introduction, Conclusion)阅读, 精读</li><li>做笔记/ 脑图</li><li>构建知识体系, 认清工作在literature中的位置和意义</li></ol><h3 id="读论文不是读教材">读论文不是读教材</h3><p>读论文是做科研最简单的方法.</p><ol type="1"><li>学方法: 不仅仅学算法, 而是学习提出, 分析, 解决, 验证, 讨论问题的方法. 不同类型工作有不同的套路.</li><li>找问题</li><li>建立知识结构: 与其他工作的联系?放在我综述的什么位置?和我工作的联系?<ol type="1"><li>启发: 想法可借鉴</li><li>基础: 可直接作为基础</li><li>靶子: 存在我针对的问题</li><li>资源: 提供了可用的数据和工具</li><li>套路: 工作方式可以借鉴(问题描述与分析, 实验设计, 图标形式, 讨论角度)</li></ol></li></ol><p><strong>要学会批判!</strong></p><p><strong>创新点: 问题和方法双向奔赴</strong>!</p><h2 id="动手尝试">动手尝试</h2><ol type="1"><li>重现已有工作: 寻找研究方向的开源项目, 实现一些尝试性的baseline</li><li>在实践中理解问题: 在一些数据上跑例子, 体会该任务的形式, 过程和常见困难, 挑战和错误</li><li>成为专家: 在创新之前先做到能熟练掌握已有技术. 设想有人来请你解决你正在研究的具体任务, 可以做到的最佳水平</li></ol><h2 id="撰写综述">撰写综述</h2><ol type="1"><li>里程碑: 代表已经是该领域专家</li><li>高屋建瓴: 从此任何工作不再孤立, 而是编制成网, 创新就在网络中诞生</li><li>用途广泛: 学位论文, 小论文, 演讲都会用到综述, 综述可以单独发表</li><li>综述也是创新: 综述核心不是罗列了哪些工作, 而是组织工作的线索. 不同的综述指引不同的研究方向.</li></ol><h2 id="寻找创新点">寻找创新点</h2><h3 id="找问题">找问题</h3><h4 id="从真实需求找问题">从真实需求找问题</h4><p>实际应用中有什么尚未解决的真实需求(工程)?有什么尚未回答的关键问题(科学)?</p><p><strong>创新</strong>: 提出新问题是最有价值的</p><h4 id="从问题定义找问题">从问题定义找问题</h4><p>当前的问题定义或解决方案基于何种假设?与真实需求存在什么差异?</p><p><strong>创新</strong>: 将如何打破假设, 缩小与真实情况的差距作为问题, 等于提出了新问题</p><h4 id="从现有方法的共性找问题">从现有方法的共性找问题</h4><p>现有方法是否有某种共同点, 如果能够突破这个共同点就是重大的新思想</p><h4 id="从方法缺陷找问题">从方法缺陷找问题</h4><p>当前方法的结果和实际需求有什么宏观的差距?</p><p><strong>创新</strong>: 比较常见的方式, 没有提出新问题</p><h4 id="从实验结果找问题">从实验结果找问题</h4><p>将现有方法的实验结果和ground truth有何差别?</p><p><strong>创新</strong>: 归纳共性错误, 将解决共性错误作为问题. 发现共性错误等于提出了新问题</p><h4 id="从前人经验找问题">从前人经验找问题</h4><p>论文在discuss和conclusion部分提出的不足和未来规划</p><p><strong>创新</strong>: 解决前人提出的问题, 没有提出新问题</p><h3 id="找方法">找方法</h3><h4 id="具有普适性新方法的引入">具有普适性新方法的引入</h4><p>将一个具有普遍意义的前沿新方法用在你的问题上. 也可以将你自己提出来的新方法应用于不同任务</p><h4 id="相关任务的类比"><strong>相关任务的类比</strong></h4><p>通过对任务的抽象, 找到可以类比的任务, 并借用改任务的思想.</p><p>推荐此方法!</p><h4 id="相关方法的整合">相关方法的整合</h4><p>现有几个方法可以解决我的问题的一部分, 将他们有机整合</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202210041623996.png" alt="" /><figcaption>image-20221004162320989</figcaption></figure><p><strong>启动研究的四大前提:</strong></p><ol type="1"><li>清晰的定义问题</li><li>准备数据</li><li>确定评价方法</li><li>确定baseline</li></ol><h2 id="定义问题">定义问题</h2><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202210041626108.png" alt="" /><figcaption>image-20221004162559909</figcaption></figure><h2 id="搜集数据">搜集数据</h2><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202210041630765.png" alt="" /><figcaption>image-20221004163033742</figcaption></figure><h2 id="确定评价方法">确定评价方法</h2><p>确定用于评价工作结果好坏的指标和方法</p><ul><li>与相关文献保持基本一致</li><li>评价所需条件</li><li>整体评价</li><li>Case study</li><li>图标设计</li></ul><h2 id="思考解决方案">思考解决方案</h2><p>思考自己的解决方案, 即论文的核心创新点: 方法参考(5)</p><ul><li>发现问题, 分析问题, 解决问题</li><li>核心思想</li><li>与现有方法的关系</li><li>核心创新点</li><li>形式化</li><li>典型例子</li></ul><h2 id="设计实验">设计实验</h2><ol type="1"><li>核心实验: 证明我的方法比其他方法好或者达到预期标准</li><li>辅助实验: 证明你的方法中细节设定是合理的(预实验, 消融实验)</li></ol><h2 id="撰写论文">撰写论文</h2><ol type="1"><li>撰写论文提纲: 论文提纲要先于着手实验, 因为撰写提纲的过程是进一步深入思考的过程, 可能发现方案的问题</li><li>完成baseline: 现成代码或自己复现, 或直接使用相同数据集</li><li>实验: 修改方案不断迭代</li><li>完成论文</li></ol><p><strong>最后, 完成比完美更重要!</strong></p><h1 id="reference">Reference</h1><p><a href="https://www.bilibili.com/video/BV1LZ4y187yN/?is_story_h5=false&amp;p=1&amp;share_from=ugc&amp;share_medium=iphone&amp;share_plat=ios&amp;share_session_id=F568A055-2D76-41A9-BF5B-F579788647CE&amp;share_source=WEIXIN&amp;share_tag=s_i&amp;timestamp=1663324248&amp;unique_k=fgOxZAn&amp;vd_source=611966b57fa4b61cacdc722ef95080e3">研究生如何做科研</a></p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>科研</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Roberta base chinese extractive qa</title>
    <link href="/2022/05/29/2022-05-29-%E6%8A%BD%E5%8F%96%E5%BC%8F%E4%B8%AD%E6%96%87QA/"/>
    <url>/2022/05/29/2022-05-29-%E6%8A%BD%E5%8F%96%E5%BC%8F%E4%B8%AD%E6%96%87QA/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>抽取式中文QA模型baseline</p><span id="more"></span><h1 id="模型使用过程">模型使用过程</h1><p>本次需要做一个抽取式中文阅读理解的baseline，在hugging face上找到了如下模型：<a href="https://huggingface.co/uer/roberta-base-chinese-extractive-qa">roberta-base-chinese-extractive-qa</a>，目前而言当作baseline没有问题。</p><p>此模型使用<a href="https://github.com/dbiir/UER-py">UER-py</a>辅助微调，在预训练模型 <a href="https://huggingface.co/uer/chinese_roberta_L-12_H-768">chinese_roberta_L-12_H-768</a>（L为layers，H为hidden sizes）的基础上对序列长度为512的三个 epoch进行微调。在每个epoch结束时，当开发集的最佳性能达到时，模型被保存。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">python3 run_cmrc.py --pretrained_model_path models/cluecorpussmall_roberta_base_seq512_model.<span class="hljs-built_in">bin</span>-<span class="hljs-number">250000</span> \<br>                    --vocab_path models/google_zh_vocab.txt \<br>                    --train_path extractive_qa.json \<br>                    --dev_path datasets/cmrc2018/dev.json \<br>                    --output_model_path models/extractive_qa_model.<span class="hljs-built_in">bin</span> \<br>                    --learning_rate <span class="hljs-number">3e-5</span> --epochs_num <span class="hljs-number">3</span> --batch_size <span class="hljs-number">32</span> --seq_length <span class="hljs-number">512</span><br></code></pre></td></tr></table></figure><p>训练数据为 <a href="https://github.com/ymcui/cmrc2018">cmrc2018</a>，<a href="https://spaces.ac.cn/archives/4338">webqa</a>，<a href="https://www.kesci.com/home/competition/5d142d8cbb14e6002c04e14a/content/0">laisi</a>。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install transformers<br>pip install pytorch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForQuestionAnswering,AutoTokenizer,pipeline<br>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;roberta-base-chinese-extractive-qa&#x27;</span>)<br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;roberta-base-chinese-extractive-qa&#x27;</span>)<br>QA = pipeline(<span class="hljs-string">&#x27;question-answering&#x27;</span>, model=model, tokenizer=tokenizer)<br>QA_input = &#123;<span class="hljs-string">&#x27;question&#x27;</span>: <span class="hljs-string">&quot;著名诗歌《假如生活欺骗了你》的作者是&quot;</span>,<span class="hljs-string">&#x27;context&#x27;</span>: <span class="hljs-string">&quot;普希金从那里学习人民的语言，吸取了许多有益的养料，这一切对普希金后来的创作产生了很大的影响。这两年里，普希金创作了不少优秀的作品，如《囚徒》、《致大海》、《致凯恩》和《假如生活欺骗了你》等几十首抒情诗，叙事诗《努林伯爵》，历史剧《鲍里斯·戈都诺夫》，以及《叶甫盖尼·奥涅金》前六章&quot;</span>&#125;<br>QA(QA_input)<br></code></pre></td></tr></table></figure><p>结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9766426682472229</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;普希金&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><h1 id="roberta-论文解读">roberta 论文解读</h1><p>论文：<a href="https://arxiv.org/pdf/1907.11692.pdf">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></p><h2 id="abstract">Abstract</h2><ol type="1"><li>预训练模型在语言模型中起到了很大的作用，但是训练成本很高。并且很多预训练模型都是使用不同大小的私有数据集进行训练，<strong>超参数的选择</strong>也会直接对结果产生影响。</li><li>Bert模型没有充分得到训练，但是仍然可以超过其他模型的效果。</li></ol><h2 id="introduction">1.Introduction</h2><p>提出了一个改进的BERT模型训练配方，我们称之为<strong>RoBERTa</strong>（A Robustly Optimized BERT），它可以匹配或超过post-BERT模型的性能。我们的修改如下：</p><ol type="1"><li>在更多的数据上用更大的批次训练模型</li><li>移除了Bert模型中next sentence prediction objective</li><li>在更长的序列上进行训练</li><li>动态地改变应用于训练数据的掩蔽模式</li></ol><p>还收集了一个新的大型数据集（CC-NEWS），其规模与其他私人使用的数据集相当，以更好地控制训练集的规模效应。</p><p>在GLUE和SQuAD上取得较好成果。</p><p>本文主要贡献有：</p><ol type="1"><li>提出了一套重要的BERT设计选择和训练策略，并引入了能够提高下游任务性能的备选方案</li><li>使用了一个新的数据集CCNEWS，并确认使用更多的数据进行预训练可以进一步提高下游任务的性能</li><li>训练改进表明，在正确的设计选择下，屏蔽语言模型预训练与所有其他最近发表的方法都更具有竞争力。</li></ol><h2 id="background">2.Background</h2><h3 id="setup">2.1 Setup</h3><p>BERT将两个片段的连接作为输入：<span class="math inline">\(x_1,...,x_N\)</span>和<span class="math inline">\(y_1,...,y_M\)</span>，段落通常由一个以上的自然句组成。这两个片段作为一个单一的输入序列呈现给BERT，并以特殊的标记为它们划界：<span class="math inline">\([CLS],x_1,...,x_N,[SEP],y_1,...,y_M,[EOS]\)</span>，<span class="math inline">\(M+N &lt; T\)</span>，T是训练期间的最大序列长度。</p><p>该模型首先在一个大型的无标签文本语料库中进行预训练，随后使用终端任务的标签数据进行微调。</p><h3 id="architecture">2.2 Architecture</h3><p>使用 L layers. Each block uses A self-attention heads and hidden dimension H的transformer结构</p><h3 id="training-objectives">2.3 Training Objectives</h3><p>在预训练期间，BERT使用了两个方法：<strong>遮蔽语言建模和下一句话预测</strong>。</p><h4 id="masked-language-model-mlm">Masked Language Model (MLM)</h4><p>在输入序列中选择一个随机的标记token，用特殊的标记[MASK]代替。MLM的目标是预测被屏蔽token的交叉熵损失。BERT均匀地选择15%的输入token进行可能的替换。在所选的token中，80%被替换为[MASK]，10%保持不变，10%被随机选择的词汇标记所替换。在最初的实现中，随机屏蔽和替换在开始时进行一次，并在训练过程中保存，尽管在实践中，数据是重复的，所以每个训练句子的屏蔽并不总是相同的。</p><h4 id="next-sentence-prediction-nsp">Next Sentence Prediction (NSP)</h4><p>NSP是一种二元分类损失，用于预测原始文本中的两个片段是否相互跟随。正面例子是通过从文本语料库中抽取连续的句子来创建的。负面的例子是通过将不同文件中的片段配对来创建的。正面和负面的例子是以相同的概率取样的。NSP目标是为了提高下游任务的性能，这需要推理成对的句子之间的关系。</p><h3 id="optimization">2.4 Optimization</h3><p>BERT模型使用的是Adam优化器，超参数<span class="math inline">\(\beta_1\)</span> = 0.9, <span class="math inline">\(\beta_2\)</span> = 0.999, <span class="math inline">\(\epsilon\)</span> = 1e-6，权重衰减参数为0.01，学习率在前10000步逐渐增加到1e-4，然后线性衰减，dropout参数为0.1，batch=256，token_length=512。</p><h3 id="data">2.5 Data</h3><p>在BOOKCORPUS和英语WIKIPEDIA的组合上进行训练</p><h2 id="experimental-setup">3 Experimental Setup</h2><ol type="1"><li>实验的超参数基本沿用了Bert模型的参数</li><li>文章发现模型结果对于Adam优化器的参数很敏感。经过对比发现当训练更大的batch时，设置<span class="math inline">\(\beta_2\)</span> = 0.98更为稳定。</li><li>原始Bert模型中，在训练过程的前90%的时候，采用了随机注入短序列的方法。本文的实验中全部使用的是足够长度的序列。</li></ol><h2 id="training-procedure-analysis">4 Training Procedure Analysis</h2><h3 id="static-vs.-dynamic-masking">4.1 Static vs. Dynamic Masking</h3><p>最原始的Bert模型采用的是静态mask，也就是选取序列中的15%个token进行mask，然后在训练过程中保持不变。RoBERTa模型<strong>为了避免每次都使用相同的mask，采用了改进版本的静态mask</strong>。具体上，同一个训练数据被重复10次，10次都使用不同的mask，然后训练40个epochs。</p><p>此外，作者还提出了动态mask，每次想模型输入数据，都使用不同的mask。</p><p>结果如图：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205292009316.png" alt="" /><figcaption>image-20220529200908276</figcaption></figure><p>采用动态mask效果会稍微好一点</p><h3 id="model-input-format-and-next-sentence-prediction">4.2 Model Input Format and Next Sentence Prediction</h3><p>在原始的Bert模型中，原文作者认为Next Sentence Prediction对于模型起到很重要的作用。<strong>但是最近的研究表明，NSP或许是可以删去的。</strong>为了比较区别，做了如下的对照试验：</p><ol type="1"><li>SEGMENT-PAIR+NSP：和原始的bert模型一致，<strong>有NSP损失</strong>。每个输入都有一对片段，每个片段可以包含多个自然句子，但总的综合长度必须小于512个标记。（<strong>片段级别</strong>）</li><li>SENTENCE-PAIR+NSP：每个输入包含一对自然句子，可以从一个文件的连续部分取样，也可以从不同的文件中取样。由于这些输入明显短于512个标记，我们增加了批量大小，使标记的总数保持与SEGMENT-PAIR+NSP相似。<strong>保留了NSP的损失</strong>。（<strong>句子级别</strong>）</li><li>FULL-SENTENCES：每个输入都是由从一个或多个文件中连续取样的完整句子组成，因此总长度最多为512个符号。输入的句子可以跨越文件的边界。当我们到达一个文件的末尾时，我们开始从下一个文件中取样，并在文件之间增加一个额外的分隔符。<strong>去除NSP的损失</strong>。<strong>存在跨文档的可能性</strong></li><li>DOC-SENTENCES：输入的构造与FULL-SENTENCES类似，只是它们不能跨越文档的边界。在文档末尾附近取样的输入可能短于512个标记，所以我们在这些情况下动态地增加批处理量，以达到与FULLSENTENCES相似的总标记数。<strong>去除NSP的损失</strong>，<strong>不存在跨文档的可能性</strong>。</li></ol><p>结果如图：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205292015268.png" alt="" /><figcaption>image-20220529201512128</figcaption></figure><p><strong>发现移除NSP会比原始Bert模型稍微好一点</strong>。FULL-SENTENCES和DOC-SENTENCES则是差不多效果</p><h3 id="training-with-large-batches">4.3 Training with large batches</h3><p>过去在神经机器翻译方面的工作表明，当学习率适当提高时，使用<strong>非常大的小批量</strong>进行训练可以提高优化速度和结束任务的性能。最近的研究表明，<strong>BERT也可以接受大批量培训</strong>原始的Bert模型使用batchsize=256的模型训练1M个step，这等价于batchsize=2K的模型训练125K个step，等价于batchsize=8K训练31K个step。结果如图：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205292017892.png" alt="" /><figcaption>image-20220529201700824</figcaption></figure><p>大批量的训练提高了屏蔽语言建模目标的复杂性，以及最终任务的准确性。通过分布式数据并行训练，大批量也更容易并行化，在随后的实验中，使用8K序列的批量进行训练。</p><h3 id="text-encoding">4.4 Text Encoding</h3><p>Byte-Pair Encoding（BPE）采用的是字符级和单词级的混合特征，该编码方案可以处理自然语言语料库中常见的大量词汇。BPE不依赖于完整的单词，而是依赖于子词(sub-word)单元。两种BPE实现方式：</p><ul><li>基于 char-level ：原始 BERT 的方式，它通过对输入文本进行启发式的词干化之后处理得到。</li><li>基于 bytes-level：与 char-level 的区别在于bytes-level 使用 bytes 而不是 unicode 字符作为 sub-word 的基本单位，因此可以编码任何输入文本而不会引入 UNKOWN 标记。</li></ul><p>本文采用byte-level BPE，这样能使模型获得更多可学习的参数。</p><h2 id="roberta">5 RoBERTa</h2><p><strong>RoBERTa模型是整合上述改进而提出来的模型。</strong></p><p><strong>RoBERTa模型采用动态masking、FULL-SENTENCES without NSP、更多的小批量、byte-level BPE。</strong></p><p>首先按照BERT-Large架构（L=24，H=1024，A=16）对RoBERTa进行训练。用BOOKCORPUS和WIKIPEDIA数据集进行了100K步预训练。使用1024块V100 GPU对模型进行了大约一天的预训练。</p><p>RoBERTa的开发集结果如下图，因为预先训练了更多数据（16GB→160GB的文本）和预训练更长时间（100K→300K→500K步），每行累积上述行的改进。RoBERTa与BERTLARGE的架构和训练目标一致。</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205301039368.png" alt="" /><figcaption>image-20220530103938275</figcaption></figure><p>在GLUE上的结果：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205301056226.png" alt="" /><figcaption>image-20220530105614211</figcaption></figure><p>在SQuAD上的结果：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205301057217.png" alt="" /><figcaption>image-20220530105701438</figcaption></figure><p>在RACE上的结果：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205301057180.png" alt="" /><figcaption>image-20220530105714448</figcaption></figure><h2 id="related-work">6 Related Work</h2><p>预训练方法的设计有不同的训练目标，包括语言建模、机器翻译和屏蔽语言模型。最近的许多论文都采用了为每个终端任务微调模型的基本配方，并以某种变体的遮蔽语言模型目标进行预训练。然而，较新的方法通过多任务微调、纳入实体嵌入、跨度预测和自回归预训练的多种变体来提高性能。通过在更多的数据上训练更大的模型，通常也能提高性能。我们的目标是复制、简化和更好地调整BERT的训练，作为一个参考点，以更好地了解所有这些方法的相对性能。</p><h2 id="conclusion">7 Conclusion</h2><p>在预训练BERT模型时，本文仔细评估一些设计决策。通过<strong>对模型进行更长时间的训练，在更多的数据上进行大批量的训练；取消下一句话的预测目标；在更长的序列上进行训练；以及动态地改变应用于训练数据的掩蔽模式可以大大改善性能</strong>。上述预训练改进方案，即为本文所提出的RoBERTa，该方案在GLUE，RACE和SQuAD上实现了目前最好的结果。备注：在GLUE上没有进行多任务微调，在SQuAD上没有使用附加数据。这些结果说明这些先前被忽视的设计决策的重要性，并表明BERT的预训练目标与最近提出的替代方案相比仍然具有竞争性。</p><h1 id="reference">reference</h1><p><a href="https://huggingface.co/uer/roberta-base-chinese-extractive-qa">roberta-base-chinese-extractive-qa</a></p><p><a href="https://github.com/dbiir/UER-py">UER-py</a></p><p><a href="https://huggingface.co/uer/chinese_roberta_L-12_H-768">chinese_roberta_L-12_H-768</a></p><p><a href="https://github.com/ymcui/cmrc2018">cmrc2018</a></p><p><a href="https://spaces.ac.cn/archives/4338">webqa</a></p><p><a href="https://www.kesci.com/home/competition/5d142d8cbb14e6002c04e14a/content/0">laisi</a></p><p><a href="https://arxiv.org/pdf/1907.11692.pdf">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>QA模型</tag>
      
      <tag>抽取式</tag>
      
      <tag>中文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CoQA A Conversational Question Answering Challenge</title>
    <link href="/2022/05/24/2022-05-24-CoQA%20A%20Conversational%20Question%20Answering%20Challenge/"/>
    <url>/2022/05/24/2022-05-24-CoQA%20A%20Conversational%20Question%20Answering%20Challenge/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>阅读论文CoQA: A Conversational Question Answering Challenge并进行整理</p><span id="more"></span><h1 id="abstract">Abstract</h1><p>人类通过涉及一系列相互联系的问题和答案的对话来收集信息。因此，要让机器协助收集信息，就必须让它们能够回答对话问题。</p><p>CoQA：一个用于建立对话式问题回答（Conversational Question Answering）系统的新型数据集。数据集包含12.7万个带答案的问题，这些问题来自7个不同领域的8千条文本段落的对话。问题是对话式的，而答案是自由格式的文本，并在段落中突出了相应的证据。</p><p>深入分析CoQA后发现对话式问题具有现有的阅读理解数据集中不存在的，挑战性的现象，例如核心推理和实用性推理。</p><p>在CoQA上评估了强大的对话和阅读理解模型。最好的系统获得了65.4%的F1分数，比人类的表现（88.8%）落后23.4分，这表明有很大的改进空间。</p><p>开源项目地址： https://stanfordnlp.github.io/coqa</p><h1 id="introduction">1 Introduction</h1><p>我们问其他人一个问题，以寻求或测试他们对某个主题的知识。根据他们的回答，我们再追问一个问题，而他们的第二个答案则建立在已经讨论过的内容之上。这种渐进的方面使人类的对话变得简洁。无法以这种方式建立和维持共同点是虚拟助手通常看起来不像是合格的对话伙伴的部分原因。</p><p>在本文中，我们介绍了CoQA，一个用于测量机器参与问题回答式对话的能力的对话问题回答数据集。在CoQA中，机器必须理解一段文字，并回答对话中出现的一系列问题。我们开发CoQA有三个主要目标。</p><h2 id="还原人类对话的性质the-nature-of-questions-in-a-human-conversation">1.还原人类对话的性质（the nature of questions in a human conversation）</h2><p>下图1显示了两个正在阅读一段话的人之间的对话</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205241511813.png" alt="" /><figcaption>image-20220524151156858</figcaption></figure><center><p>图1 CoQA数据集中的一个对话</p></center><p>一个作为提问者，另一个作为回答者。在这个对话中，第一个问题之后的每个问题都取决于对话历史。例如，Q5只有一个词，如果不知道已经说了什么，就不可能回答。提出简短的问题是一种有效的人类对话策略，但这样的问题对于机器来说确实很难解析。<strong>最先进的模型在很大程度上依赖于问题和段落之间的词汇相似性。目前，还没有大规模的阅读理解数据集包含依赖于对话历史的问题，而这正是CoQA的主要开发目的。</strong></p><p>CoQA与现有阅读理解数据集的比较如下表：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205241515727.png" alt="" /><figcaption>image-20220524151514762</figcaption></figure><h2 id="确保对话中答案的自然度">2.确保对话中答案的自然度</h2><p>许多现有的QA数据集将答案限制在特定段落的连续文本跨度内，这样的答案并不总是自然的。例如，在图1中的Q4。在CoQA中，我们建议答案可以是自由格式的文本，而对于每个答案，我们还提供一段文本跨度（text span）作为答案的理由（rational）。因此，Q4的答案是简单的“3”，而其理由则跨越了多个句子。</p><p>在以前的阅读理解数据集中自由形式的答案已经被研究过了，并且由于可能的答案的高差异性，BLEU或ROUGE等指标被用于评估。本文的一个关键区别是，我们要求回答者首先选择一个文本跨度作为理由，然后编辑它以获得一个自由形式的答案。我们的方法在答案的自然性和可靠的自动评估之间取得了平衡，它导致了高度的人类一致性（人类注释者之间88.8%的F1词汇重叠）。</p><h2 id="建立跨领域表现稳健的qa系统">3.建立跨领域表现稳健的QA系统</h2><p>目前的QA数据集主要集中在一个单一的领域，这使得它很难测试现有模型的泛化能力。因此，我们从七个不同的领域收集数据集：儿童故事、文学、初中和高中英语考试、新闻、维基百科、Reddit和科学。最后两个用于域外评估。</p><p>总而言之，CoQA具有以下主要特点：</p><ul><li>它由12.7万个对话回合组成，这些对话回合是从8k个文本段落的对话中收集的。平均对话长度为15个回合，每个回合由一个问题和一个答案组成。</li><li>它包含自由形式的答案，每个答案都有一个基于跨度的理由，在段落中突出显示。</li><li>它的文本段落是从七个不同的领域收集的：五个用于域内评估，两个用于域外评估。</li></ul><p>几乎一半的CoQA问题都是使用隐喻来回顾对话历史的，而且有很大一部分问题需要进行实用性推理，这对仅仅依靠词汇线索的模型来说是一个挑战。我们在最先进的对话和阅读理解模型的基础上，对几个深度神经网络模型进行了基准测试。表现最好的系统达到了65.4%的F1分数。相比之下，人类取得了88.8%的F1分数，高出23.4%的F1分数，表明还有很大的改进空间。</p><h1 id="task-definition">2 Task Definition</h1><p>任务为：给出一段话和迄今为止的对话，任务是回答对话中的下一个问题。谈话中的每个回合都包含一个问题和一个答案。</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205241622144.png" alt="" /><figcaption>image-20220524162205024</figcaption></figure><center><p>图2 一段对话以彩色显示核心推理链。焦点实体在Q4、Q5、Q6中变化</p></center><p>对于图2中的例子，对话以问题Q1开始。我们根据证据R1来回答Q1，R1是段落中的一个连续的文本跨度。在这个例子中，回答者只写了“州长”作为答案，但选择了一个较长的理由。</p><p>当我们谈到Q2时，我们必须参考对话历史。在我们的任务中，对话历史对于回答许多问题是不可缺少的。我们使用对话历史Q1和A1，证据R2来回答Q2。从形式上看，要回答<span class="math inline">\(Q_n\)</span>，取决于对话历史。Q1, A1, ..., <span class="math inline">\(Q_{n-1}, A_{n-1}\)</span>。对于一个无法回答的问题，我们给出未知数（unknown）作为最终答案，并且不强调任何理由。</p><p>在这个例子中，我们观察到<strong>焦点实体随着对话的进行而变化</strong>。在第4题中，提问者用his指代Terry，在第5题中，他指代Ken。如果这些问题没有得到正确的解决，我们最终会得到不正确的答案。<strong>问题的对话性</strong>要求我们从多个句子（当前问题和之前的问题或答案，以及段落中的句子）中进行推理。常见的情况是，一个问题可能需要跨越多个句子的推理（例如，图1中的Q1 Q4和Q5）。</p><p>我们收集理由（rationale）作为（可选）选项来帮助回答问题。但是，在测试时未提供理由。一个模型需要自己根据证据做出决定，并得出最终答案。</p><h1 id="dataset-collection">3 Dataset Collection</h1><p>对于每一次对话，我们都会聘请两位注释者，一位提问者和一位回答者。与使用单个注释者同时充当提问者和回答者相比，这种设置有几个优点：</p><ol type="1"><li>当两个注释者谈论一篇文章时，他们的对话流是自然的</li><li>当一个注释者回答一个模糊的问题或错误的答案时，另一个注释者可以进行标记</li><li>两个注释者在有分歧时可以讨论准则（通过一个单独的聊天窗口）。这些措施有助于防止spam（<a href="https://baike.baidu.com/item/SPAM/2626792">搜索引擎垃圾技术</a>），并获得高一致度的数据</li></ol><p>我们使用亚马逊机械人（AMT），通过ParlAI MTurk API对工人进行通道配对。</p><h2 id="collection-interface">3.1 Collection Interface</h2><p>我们对提问者和回答者有不同的界面。提问者的作用是提出问题，回答者的作用是回答问题，并标记理由。提问者和回答者都能看到本轮现在为止发生的对话，也就是说，之前所有轮的问题和回答以及理由都是隐藏的。</p><p>在提出新的问题时，我们希望提问者避免使用段落中的确切词汇，以增加词汇的多样性。当他们输入一个已经出现在段落中的词时，我们提醒他们尽可能地转述问题。界面如图：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205251228469.png" alt="" /><figcaption>image-20220524193802358</figcaption></figure><p>在回答问题时，我们希望回答者坚持使用段落中的词汇，以限制可能的答案数量。鼓励按如下操作：首先突出一个理由（文本跨度），然后将其自动复制到答案框中，进一步要求编辑复制的文本，以产生一个自然答案。我们发现78%的答案至少有一个编辑，如改变一个单词的大小写或添加一个标点符号。界面如图：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205251228942.png" alt="" /><figcaption>image-20220524193830556</figcaption></figure><h2 id="passage-selection">3.2 Passage Selection</h2><p>从7个领域选取段落。并非所有的段落都同样适合产生有趣的对话。一个只有一个实体的段落往往会导致问题完全集中在该实体上。因此，我们使用Stanford CoreNLP，选择具有多个实体、事件和人称参考的段落。我们将长篇文章截断到前几段，每段200字左右。</p><p>对于每个域内数据集，我们将数据分割成这样：开发集（development set，用于调整参数，选择特征，以及对学习算法作出其它决定）里有100个段落，测试集里有100个段落，其余的在训练集中。对于每个域外数据集，我们只在测试集中有100段话。</p><p>具体分布如下表：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205251229079.png" alt="" /><figcaption>image-20220524194351703</figcaption></figure><h2 id="collecting-multiple-answers">3.3 Collecting Multiple Answers</h2><p>CoQA中的一些问题可能有多个有效答案，因此在开发集和测试集中额外选取了三个答案。由于我们的数据是对话式的，问题会影响答案，而答案又会影响后续问题。为了保证对话的连贯性，通过将答案收集任务变成预测原始答案来实现：让回答者预测原始答案，尽量让回答者的答案向原始答案的方向上靠。</p><p>在我们的试点实验中，当我们使用这种验证设置时，人类的F1得分增加了5.4%。</p><h1 id="dataset-analysis">4 Dataset Analysis</h1><h2 id="comparison-with-squad-2.0">4.1 Comparison with SQuAD 2.0</h2><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205242037168.png" alt="" /><figcaption>image-20220524203700115</figcaption></figure><center><p>图3 问题在 SQuAD 和 CoQA 中的三元组前缀的分布。</p></center><p>SQuAD 2.0介绍：SQuAD 是由 Rajpurkar 等人提出的阅读理解数据集。包含 10 万个（问题，原文，答案）三元组，来自于 536 篇维基百科文章，问题和答案的构建主要是通过众包的方式，让标注人员提出最多 5 个基于文章内容的问题并提供正确答案，且答案出现在原文中。SQuAD 和之前的完形填空类阅读理解数据集如 CNN/DM，CBT等最大的区别在于：SQuAD 中的答案不再是单个实体或单词，而可能是一段短语，这使得其答案更难预测。SQuAD 包含公开的训练集和开发集，以及一个隐藏的测试集，采用与ImageNet 类似的封闭评测的方式。</p><p>CoQA与SQuAD区别：</p><ol type="1"><li>SQuAD大部分是关于what的问题，而CoQA的问题类型分布更广泛</li><li>did, was, is, does and这些词经常在CoQA中见到，但SQuAD中却很少见</li><li>SQuAD中不存在指代词，但CoQA几乎每个部分都包含指代词，体现了CoQA的对话性</li><li>CoQA的问题和答案更短（平均：5.5&lt;10.1）</li></ol><p>两个数据集都有大量的命名实体和名词短语作为答案</p><p>下表是SQuAD和CoQA答案种类的分布：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205242107699.png" alt="" /><figcaption>image-20220524210722898</figcaption></figure><h2 id="linguistic-phenomena">4.2 Linguistic Phenomena</h2><p>在开发集中抽出150个问题，并对各种现象进行注释，如下表所示：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205242108599.png" alt="" /><figcaption>image-20220524210853711</figcaption></figure><p>按问题和文章关系分类：</p><p>词汇匹配：问题包含至少一个出现在文章中的内容词（29.8 %）</p><p>释义：理由的释义，同义、反义词、上下义和否定（43.0 %）</p><p>语用学：没有词汇线索，常识和预设（27.2 %）</p><p>按问题和它的对话历史之间的关系，我们把问题分为它们是依赖于对话历史还是独立于对话历史。</p><p>不依赖于与会话历史的共指，可以自己回答（30.5 %）</p><p>包含明确的核心推理标记，如他、她、它。这些标记要么是指一个实体，要么是指对话中介绍的事件。（49.7 % ）</p><p>有明确的核心参考标记，而是隐含地指称一个实体或事件（19.8 %）</p><h2 id="analysis-of-free-form-answers">4.3 Analysis of Free-form Answers</h2><p>由于CoQA的答案是自由形式的，大约有33.2%的答案与给定的段落不完全重合。我们分析了100个对话来研究这类答案的行为。</p><p>“YES”和“NO”的答案分别占48.5%和30.3%，总共占78.8%。</p><p>对文本跨度的编辑，大约占14.3%，以提高答案的流畅性（自然度）。在这些编辑中，超过三分之二的编辑只是一个词的编辑，要么插入或删除一个词。这表明文本跨度是自然答案的一个很好的近似值，剩下的三分之一涉及多个编辑。虽然多次编辑对使用自动指标进行评估是一个挑战，但我们观察到这些答案中有许多与段落部分重叠，表明在我们的环境中，词的重叠仍然是一个可靠的自动评估指标。</p><p>其余的答案包括计数（5.1%）和从问题中选择一个选项（1.8%）。</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205242151557.png" alt="" /><figcaption>image-20220524215147398</figcaption></figure><h2 id="conversation-flow">4.4 Conversation Flow</h2><p>一个连贯的对话必须在转折之间有流畅的过渡。我们期望段落的叙事结构能够影响我们的对话流程。我们把每段话分成10个统一的小块，然后记录对话进行过程中，对十个大块的关注程度的变化情况，如下图所示：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205242155013.png" alt="" /><figcaption>image-20220524215525184</figcaption></figure><p>横轴表示对话的轮数（即第几轮问答）纵轴表示对话块的分布。从上往下（红色到深绿）依次为文章的第一块到最后一块，文中的灰色频率带宽度表示块与块之间转换的频繁程度，越频繁的转换，带宽越宽。</p><p>由图可知，最开始对话总是集中在前面几块，随着对话轮数的进行，关注点逐渐偏向后面的块（表现为红色部分逐渐减小，下方其他部分逐渐增大）块与块之间的转移表明相邻块之间的转移更加频繁。</p><h1 id="models">5 Models</h1><p>给定段落p</p><p>对话历史<span class="math inline">\({q_1,a_1,...,q_{i-1},a_{i-1}}\)</span></p><p>黄金答案<span class="math inline">\(a_1,a_2,...,a_{i-1}\)</span>被用来预测<span class="math inline">\(a_i\)</span></p><p>输入：问题<span class="math inline">\(q_i\)</span></p><p>输出：答案<span class="math inline">\(a_i\)</span></p><p>模型构成：PGNet+DrQA</p><p>我们的任务可以被建模为对话式反应生成问题或阅读理解问题。我们在CoQA上评估了两种类型的baseline以及两者的组合</p><h2 id="conversational-models">5.1 Conversational Models</h2><p>PGNet：以传统的seq2seq模型为基础，使用包含注意力模型的seq2seq生成答案</p><p>将文章，对话历史，当前问题输入双向LSTM的encoder中，在decoder中引入允许从文章中复制词语的复制机制。</p><h2 id="reading-comprehension-models">5.2 Reading Comprehension Models</h2><p>DrQA：Document Retriever + Document Reader用于根据问题找出指定范围，并根据指定范围得出问题的答案。</p><p>由于DrQA在训练过程中需要文本跨度作为答案，我们选择与原始答案有最高词汇重叠（F1得分）的跨度作为黄金答案。如果答案在故事中出现多次，我们就用rational来寻找正确的答案。如果任何答案词没有出现在故事中，我们就退回到一个额外的未知标记作为答案（在训练集中约占17%）。我们在每个问题前加上其过去的问题和答案，以说明对话历史，与对话模型类似。</p><p>考虑到我们的数据集中有很大一部分答案是 "是 "或 "否"，我们还包括一个增强的阅读理解模型作为比较。我们在段落的末尾增加了两个额外的标记，是和不是--如果黄金答案是 "是 "或 "不是"，模型就需要预测相应的标记作为黄金跨度；否则就与之前的模型相同。我们把这个模型称为增强的DrQA。</p><h2 id="a-combined-model">5.3 A Combined Model</h2><p>将DrQA与PGNet结合起来使用。在这个模型中，DrQA首先指出文本中的答案证据，而PGNet则将证据归化为答案。例如，对于图1中的Q5，我们希望DrQA首先预测出理由R5，然后PGNet从R5生成A5。</p><p>根据经验表现，我们对DrQA和PGNet做了一些改变。对于DrQA，如果答案是理由的一个子串则直接预测答案，否则就预测理由。对于PGNet，我们提供当前问题和DrQA的跨度预测作为编码器的输入，解码器的目的是预测最终的答案。</p><h1 id="evaluation">6 Evaluation</h1><h2 id="evaluation-metric">6.1 Evaluation Metric</h2><p>评估指标：根据重合度计算的F1分值</p><p>SQuAD：模型输出的每一个结果与n个人工答案进行比较，得到n个F1分值，取n个分值中最大的值作为该模型输出的F1分值。</p><h2 id="experimental-setup">6.2 Experimental Setup</h2><p>对于seq2seq和PGNet的所有实验，我们使用OpenNMT工具包及其默认设置：2层LSTM，编码器和解码器都有500个隐藏单元。这些模型使用SGD进行优化，初始学习率为1.0，衰减率为0.5。所有层都采用了0.3的退出率。</p><p>对于DrQA实验，我们使用原始论文中的实现。我们在开发数据上调整超参数：使用对话历史的回合数、层数、每层隐藏单元的数量和退出率。我们发现的最佳配置是3层LSTM，每层有300个隐藏单元。辍学率为0.4，适用于所有LSTM层，辍学率为0.5，适用于单词嵌入。我们用Adam来优化DrQA模型。</p><p>对于阅读理解模型，使用fastText进行文本分类</p><h2 id="results-and-discussion">6.3 Results and Discussion</h2><p>下表显示了模型在开发和测试数据上的结果：</p><figure><img src="C:\Users\Rien\Desktop\wenge_slides\fig\result.png" alt="" /><figcaption>image-20220525003058226</figcaption></figure><p>seq2seq模型的表现最差，它生成了频繁出现的答案，而不管这些答案是否出现在段落中，这是众所周知的对话模型的行为。</p><p>PGNet通过关注语篇中的词汇来缓解频繁出现的问题，它比seq2seq高出17.8分。然而，它仍然落后于DrQA 8.5分。一个原因可能是PGNet在回答问题前必须记住整个段落，这是DrQA避免的巨大开销。但是DrQA在回答那些答案与文段不重合的问题时却惨遭失败（见表8中的No span行）。</p><p>增强后的DrQA用额外的是/否标记规避了这个问题，使其提高了12.8分。</p><p>当DrQA被送入PGNet时，我们同时增强了DrQA和PGNet的能力--DrQA产生自由形式的答案；PGNet则专注于理由而不是段落的内容。这种组合比普通的PGNet和DrQA模型分别高出21.0分和12.5分，并与增强的DrQA竞争（65.1对65.4）。</p><h3 id="models-vs.-humans">Models vs. Humans</h3><p>我们的最佳模型比人类落后23.4分。</p><h3 id="in-domain-vs.-out-of-domain">In-domain vs. Out-of-domain</h3><p>所有模型在域外数据集上的表现都比域内数据更差。最好的模型下降了6.6分。</p><p>对于领域内的结果，最好的模型和人类都发现文学领域比其他领域更难</p><p>对于领域外的结果，Reddit领域显然更难</p><h3 id="error-analysis">Error Analysis</h3><p>seq2seq和PGNet在非重叠答案上表现良好，而DrQA在重叠答案上表现良好，增强的和组合的模型在这两类问题上都有改进。</p><p>在不同的问题类型中，人类发现词汇匹配是最容易的，其次是转述，而语用学是最难的</p><h3 id="importance-of-conversation-history">Importance of conversation history</h3><p>下表显示了将不同数量的先前回合作为对话历史的结果：</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205250043643.png" alt="" /><figcaption>image-20220525004346626</figcaption></figure><p>所有的模型都成功地利用了历史，但超过一个以前的回合，收益就很少了。随着我们增加历史记录的大小，性能会下降。</p><p>在人的实验中，前一回合在理解当前问题中起着重要作用；对话中的大多数问题在两个回合的范围内有有限的依赖性。</p><h3 id="augmented-drqa-vs.-combined-model">Augmented DrQA vs. Combined Model</h3><p>虽然增强的DrQA的性能比组合模型要好一点（在测试集上为0.3 F1），但后者模型有以下好处：</p><ol type="1"><li>组合模型为每个答案提供理由，可以用来证明答案是否正确（例如，是/否问题）</li><li>我们不必事先决定增强类的集合，这有助于回答广泛的问题，如计数和多项选择（表10）</li></ol><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205250047584.png" alt="" /><figcaption>image-20220525004752631</figcaption></figure><center><p>表10 对答案与文本段落不重合的问题进行错误分析</p></center><h1 id="related-work">7 Related work</h1><p>包括Knowledge source，Naturalness ，Conversational Modeling，Reasoning，Recent progress on CoQA。</p><h1 id="conclusions">8 Conclusions</h1><p>在本文中，我们介绍了CoQA，一个用于建立对话式问题回答系统的大规模数据集。与现有的阅读理解数据集不同，CoQA包含对话式问题、自由形式的答案以及作为理由的文本跨度，以及来自七个不同领域的文本段落。我们希望这项工作能够激发更多的对话建模研究，这是实现自然人机交流的一个关键因素。</p><h1 id="reference">Reference</h1><p><a href="https://arxiv.org/abs/1808.07042">CoQA: A Conversational Question Answering Challenge</a></p><p><a href="https://blog.csdn.net/cindy_1102/article/details/88560048">【笔记1-1】基于对话的问答系统CoQA (Conversational Question Answering)</a></p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>paperReading</tag>
      
      <tag>数据集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer</title>
    <link href="/2022/05/16/2022-05-16-Transformer/"/>
    <url>/2022/05/16/2022-05-16-Transformer/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>NLP领域Transformer模型。</p><span id="more"></span><p>Transformer是seq2seq model with self-attention.</p><h1 id="seq2seq">seq2seq</h1><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161919572.png" alt="" /><figcaption>image-20220516191914583</figcaption></figure><p>seq2seq有很多应用, 这里不一一列举.</p><p>一般seq2seq model 有两个模块: encoder和decoder:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161941556.png" alt="" /><figcaption>image-20220516194154540</figcaption></figure><h1 id="encoder">encoder</h1><p>encoder作用:给一排向量, 输出另外一排向量,如图:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161943074.png" alt="" /><figcaption>image-20220516194317975</figcaption></figure><p>transformer里用的是self-attention, transformer的encoder如图:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161945590.png" alt="" /><figcaption>image-20220516194528015</figcaption></figure><p>每个block里有多个layer</p><p>上图右边是简化版本, 事实上每个block做的操作为:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162135444.png" alt="" /><figcaption>image-20220516213532551</figcaption></figure><p>图中需要做两点说明:</p><ol type="1"><li>计算<span class="math inline">\(x_i^{&#39;}\)</span>时等号右边为<span class="math inline">\(x_i\)</span></li><li>左边norm的输出是右边FC的输入</li></ol><p>右边norm的输出就是一个block的输出.</p><h1 id="decoder">decoder</h1><p>decoder作用为产生输出.</p><h2 id="at">AT</h2><p>decoder将encoder的输出先读入, 给decoder一个特殊符号表示开始BOS(begin of sentence), decoder读到特殊符号后会输出一个向量, 该向量和vocabulary的长度相同. 在产生输出向量之前都会做softmax, 该向量会给每一个元素一个值, 值最大的就是输出. 如图所示:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162153701.png" alt="" /><figcaption>image-20220516215338595</figcaption></figure><p>将这个输出连同BOS当作输入, 再得到下一个输出:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162154606.png" alt="" /><figcaption>image-20220516215408696</figcaption></figure><p>如此重复:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162155365.png" alt="" /><figcaption>image-20220516215557890</figcaption></figure><p>对比encoder和decoder内部结构:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162156026.png" alt="" /><figcaption>image-20220516215655970</figcaption></figure><p>如果把decoder的中间遮住:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162157067.png" alt="" /><figcaption>image-20220516215720200</figcaption></figure><p>encoder和decoder是一样的. 只是decoder最后会做一个softmax得到几率</p><p>不一样之处在于decoder还有一个mask. masked self-attention和self-attention有一定区别, 下面列举出的图片可以和<a href="https://rien190.github.io/2022/05/15/self-attentionn.html#self-attention%E6%A8%A1%E5%9E%8B">Self-Attention机制</a>中图片进行对比理解</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162200110.png" alt="" /><figcaption>image-20220516220016462</figcaption></figure><p>每次产生的vector只能看到前面的vector, eg <span class="math inline">\(b^2\)</span>只能看到<span class="math inline">\(a^1和a^2\)</span>.</p><p>更具体来说:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162205736.png" alt="" /><figcaption>image-20220516220535863</figcaption></figure><p>因为在self-attention中<span class="math inline">\(a^1到a^4\)</span>是同时出现的, 而在decoder中<span class="math inline">\(a^1到a^4\)</span>是顺序出现的.</p><p>还有问题需要处理: decoder需要决定输出的长度. 所以需要END符. 如图:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162213307.png" alt="" /><figcaption>image-20220516221311870</figcaption></figure><h2 id="nat-vs-at">NAT vs AT</h2><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162225367.png" alt="" /><figcaption>image-20220516222536334</figcaption></figure><h2 id="cross-attention">Cross attention</h2><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162227503.png" alt="" /><figcaption>image-20220516222735582</figcaption></figure><p>实际运作过程:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162229991.png" alt="" /><figcaption>image-20220516222918178</figcaption></figure><h1 id="training">Training</h1><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205162241023.png" alt="" /><figcaption>image-20220516224154992</figcaption></figure><p>训练时需要缩小decoder的输出与正确答案之间的差距,训练时decoder的输入为正确答案</p><h1 id="reference">reference</h1><p><a href="https://www.youtube.com/watch?v=ugWDIIOHtPA">Transformer 李宏毅</a></p><p><a href="https://rien190.github.io/2022/05/15/self-attentionn.html#self-attention%E6%A8%A1%E5%9E%8B">Self-Attention机制</a></p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Self-Attention机制</title>
    <link href="/2022/05/15/2022-05-15-self-attentionn/"/>
    <url>/2022/05/15/2022-05-15-self-attentionn/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><p>NLP领域Transformer模型中self-attention机制</p><span id="more"></span><h1 id="前言">前言</h1><p>注意力模型最近几年在深度学习各个领域被广泛使用，无论是图像处理、语音识别还是自然语言处理的各种不同类型的任务中，都很容易遇到注意力模型的身影。</p><p>从注意力模型的命名方式看，很明显其借鉴了人类的注意力机制:视觉注意力机制是人类视觉所特有的大脑信号处理机制。人类视觉通过快速扫描全局图像，获得需要重点关注的目标区域，也就是一般所说的注意力焦点，而后对这一区域投入更多注意力资源，以获取更多所需要关注目标的细节信息，而抑制其他无用信息。这是人类利用有限的注意力资源从大量信息中快速筛选出高价值信息的手段，是人类在长期进化中形成的一种生存机制，人类视觉注意力机制极大地提高了视觉信息处理的效率与准确性。</p><p>深度学习中的注意力机制从本质上讲和人类的选择性视觉注意力机制类似，核心目标也是从众多信息中选择出对当前任务目标更关键的信息。</p><h1 id="encoder-decoder框架">Encoder-Decoder框架</h1><p>Encoder-Decoder框架可以看作是一种深度学习领域的研究模式，应用场景异常广泛。目前大多数注意力模型附着在Encoder-Decoder框架下，当然，其实注意力模型可以看作一种通用的思想，本身并不依赖于特定框架.</p><p>文本处理领域的Encoder-Decoder框架可以这么直观地去理解：可以把它看作适合处理由一个句子（或篇章）生成另外一个句子（或篇章）的通用处理模型。对于句子对&lt;Source,Target&gt;，我们的目标是给定输入句子Source，期待通过Encoder-Decoder框架来生成目标句子Target。Source和Target可以是同一种语言，也可以是两种不同的语言。</p><p>Source和Target分别由各自的单词序列构成：</p><p><span class="math display">\[Source = &lt;x_1,x_2,...,x_m&gt; \\Target=&lt;y_1,y_2,...,y_n&gt;\]</span></p><p>Encoder顾名思义就是对输入句子Source进行编码，将输入句子通过非线性变换转化为中间语义表示C： <span class="math display">\[C=\mathcal{F}(x_1,x_2,...,x_m)\]</span> 对于解码器Decoder来说，其任务是根据句子Source的中间语义表示C和之前已经生成的历史信息<span class="math inline">\(y_1,y_2,...,y_{i-1}\)</span>来生成i时刻要生成的单词<span class="math inline">\(y_i\)</span>:</p><p><span class="math display">\[y_i=\mathcal{G}(C,y_1,y_2,...,y_{i-1})\]</span></p><p>每个<span class="math inline">\(y_i\)</span>都依次这么产生，那么看起来就是整个系统根据输入句子Source生成了目标句子Target。如果Source是中文句子，Target是英文句子，那么这就是解决机器翻译问题的Encoder-Decoder框架；如果Source是一篇文章，Target是概括性的几句描述语句，那么这是文本摘要的Encoder-Decoder框架；如果Source是一句问句，Target是一句回答，那么这是问答系统或者对话机器人的Encoder-Decoder框架。由此可见，在文本处理领域，Encoder-Decoder的应用领域相当广泛。</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205151717314.png" title="图1 抽象的文本处理领域的Encoder-Decoder框架" alt="" /><figcaption>image-20220515135444239</figcaption></figure><center><p>图1 抽象的文本处理领域的Encoder-Decoder框架</p></center><p>Encoder-Decoder框架不仅仅在文本领域广泛使用，在语音识别、图像处理等领域也经常使用。比如对于语音识别来说，图1所示的框架完全适用，区别无非是Encoder部分的输入是语音流，输出是对应的文本信息；而对于“图像描述”任务来说，Encoder部分的输入是一副图片，Decoder的输出是能够描述图片语义内容的一句描述语。一般而言，文本处理和语音识别的Encoder部分通常采用RNN模型，图像处理的Encoder一般采用CNN模型。</p><h1 id="attention模型">Attention模型</h1><p>本节先以机器翻译作为例子讲解最常见的Soft Attention模型的基本原理，之后抛离Encoder-Decoder框架抽象出了注意力机制的本质思想，然后简单介绍最近广为使用的Self Attention的基本思路。</p><h2 id="soft-attention模型">Soft Attention模型</h2><p>图1中展示的Encoder-Decoder框架是没有体现出“注意力模型”的，所以可以把它看作是注意力不集中的分心模型。为什么说它注意力不集中呢？请观察下目标句子Target中每个单词的生成过程如下：</p><p><span class="math display">\[\begin{align}y_1=&amp;f(C)\\y_2=&amp;f(c,y_1)\\y_3=&amp;f(c,y_1,y_2)\end{align}\]</span></p><p>其中f是Decoder的非线性变换函数。从这里可以看出，在生成目标句子的单词时，不论生成哪个单词，它们使用的输入句子Source的语义编码C都是一样的，没有任何区别。</p><p>而语义编码C是由句子Source的每个单词经过Encoder 编码产生的，这意味着不论是生成<span class="math inline">\(y_1,y_2,y_3\)</span>哪个单词,其实句子Source中任意单词对生成某个目标单词<span class="math inline">\(y_i\)</span>来说影响力都是相同的，这是为何说这个模型没有体现出注意力的缘由。这类似于人类看到眼前的画面，但是眼中却没有注意焦点一样。</p><p>如果拿机器翻译来解释这个分心模型的Encoder-Decoder框架更好理解，比如输入的是英文句子：Tom chase Jerry，Encoder-Decoder框架逐步生成中文单词：“汤姆”，“追逐”，“杰瑞”。在翻译“杰瑞”这个中文单词的时候，分心模型里面的每个英文单词对于翻译目标单词“杰瑞”贡献是相同的，很明显这里不太合理，显然“Jerry”对于翻译成“杰瑞”更重要，但是分心模型是无法体现这一点的，这就是为何说它没有引入注意力的原因。</p><p>没有引入注意力的模型在输入句子比较短的时候问题不大，但是如果输入句子比较长，此时所有语义完全通过一个中间语义向量来表示，单词自身的信息已经消失，可想而知会丢失很多细节信息，这也是为何要引入注意力模型的重要原因。</p><p>上面的例子中，如果引入Attention模型的话，应该在翻译“杰瑞”的时候，体现出英文单词对于翻译当前中文单词不同的影响程度，比如给出类似下面一个概率分布值：</p><p><span class="math display">\[(Tom,0.3)(Chase,0.2) (Jerry,0.5)\]</span></p><p>每个英文单词的概率代表了翻译当前单词“杰瑞”时，注意力分配模型分配给不同英文单词的注意力大小。这对于正确翻译目标语单词肯定是有帮助的，因为引入了新的信息。</p><p>同理，目标句子中的每个单词都应该学会其对应的源语句子中单词的注意力分配概率信息。这意味着在生成每个单词的时候，原先都是相同的中间语义表示C会被替换成根据当前生成单词而不断变化的<span class="math inline">\(C_i\)</span>。<strong>理解Attention模型的关键就是这里，即由固定的中间语义表示C换成了根据当前输出单词来调整成加入注意力模型的变化的<span class="math inline">\(C_i\)</span>。</strong>增加了注意力模型的Encoder-Decoder框架理解起来如图2所示:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205151821033.png" alt="" /><figcaption>image-20220515141236033</figcaption></figure><center><p>图2 引入注意力模型的Encoder-Decoder框架</p></center><p>即生成目标句子单词的过程成了下面的形式：</p><p><span class="math display">\[\begin{align}y_1 = &amp;f_1(C_1)\\y_2 = &amp;f_1(C_2,y_1)\\y_3 = &amp;f_1(C_3,y_1,y_2)\end{align}\]</span></p><p>而每个<span class="math inline">\(C_i\)</span>可能对应着不同的源语句子单词的注意力分配概率分布，比如对于上面的英汉翻译来说，其对应的信息可能如下：</p><p><span class="math display">\[\begin{align}C_{汤姆} = &amp;g(0.6*f_2(&quot;Tom&quot;),0.2*f_2(&quot;chase&quot;),0.2*f_2(&quot;Jerry&quot;))\\C_{追逐} = &amp;g(0.2*f_2(&quot;Tom&quot;),0.7*f_2(&quot;chase&quot;),0.1*f_2(&quot;Jerry&quot;))\\C_{杰瑞} = &amp;g(0.3*f_2(&quot;Tom&quot;),0.2*f_2(&quot;chase&quot;),0.5*f_2(&quot;Jerry&quot;))\\\end{align}\]</span></p><p>其中，<span class="math inline">\(f_2\)</span>函数代表Encoder对输入英文单词的某种变换函数，比如如果Encoder是用的RNN模型的话，这个<span class="math inline">\(f_2\)</span>函数的结果往往是某个时刻输入<span class="math inline">\(x_i\)</span>后隐层节点的状态值；g代表Encoder根据单词的中间表示合成整个句子中间语义表示的变换函数，一般的做法中，g函数就是对构成元素加权求和，即下列公式：</p><p><span class="math display">\[C_i = \sum^{L_x}_{j=1}a_{ij}h_j\]</span></p><p>其中，<span class="math inline">\(L_x\)</span>代表输入句子Source的长度，<span class="math inline">\(a_{ij}\)</span>代表在Target输出第i个单词时Source输入句子中第j个单词的注意力分配系数，而<span class="math inline">\(h_j\)</span>则是Source输入句子中第j个单词的语义编码。假设<span class="math inline">\(C_i\)</span>下标i就是上面例子所说的“ 汤姆” ，那么<span class="math inline">\(L_x\)</span>就是3，h1=f(“Tom”)，h2=f(“Chase”),h3=f(“Jerry”)分别是输入句子每个单词的语义编码，对应的注意力模型权值则分别是0.6,0.2,0.2，所以g函数本质上就是个加权求和函数。如果形象表示的话，翻译中文单词“汤姆”的时候，数学公式对应的中间语义表示<span class="math inline">\(C_i\)</span>的形成过程类似图3:</p><p><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205151822347.png" alt="image-20220515173941242" style="zoom: 67%;" /></p><center><p>图3 Attention的形成过程</p></center><p>这里还有一个问题：生成目标句子某个单词，比如“汤姆”的时候，如何知道Attention模型所需要的输入句子单词注意力分配概率分布值呢？就是说“汤姆”对应的输入句子Source中各个单词的概率分布：(Tom,0.6)(Chase,0.2) (Jerry,0.2) 是如何得到的呢？</p><p>为了便于说明，我们假设对图2的非Attention模型的Encoder-Decoder框架进行细化，Encoder采用RNN模型，Decoder也采用RNN模型，这是比较常见的一种模型配置，则图1的框架转换为图4。</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205151825368.png" alt="" /><figcaption>image-20220515182524683</figcaption></figure><center><p>图4 RNN作为具体模型的Encoder-Decoder框架</p></center><p>那么用图5可以较为便捷地说明注意力分配概率分布值的通用计算过程。</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205151931716.png" alt="" /><figcaption>image-20220515193144507</figcaption></figure><center><p>图5 注意力分配概率计算</p></center><p>对于采用RNN的Decoder来说，在时刻i，如果要生成<span class="math inline">\(y_i\)</span>单词，我们是可以知道Target在生成<span class="math inline">\(y_i\)</span>之前的时刻i-1时，隐层节点i-1时刻的输出值<span class="math inline">\(H_{i-1}\)</span>的，而我们的目的是要计算生成<span class="math inline">\(y_i\)</span>时输入句子中的单词“Tom”、“Chase”、“Jerry”对<span class="math inline">\(y_i\)</span>来说的注意力分配概率分布，那么可以用Target输出句子i-1时刻的隐层节点状态<span class="math inline">\(H_{i-1}\)</span>去一一和输入句子Source中每个单词对应的RNN隐层节点状态<span class="math inline">\(h_j\)</span>进行对比，即通过函数<span class="math inline">\(F(h_j,H_{i-1})\)</span>来获得目标单词和每个输入单词对应的对齐可能性，这个F函数在不同论文里可能会采取不同的方法，然后函数F的输出经过Softmax进行归一化就得到了符合概率分布取值区间的注意力分配概率分布数值。</p><p>绝大多数Attention模型都是采取上述的计算框架来计算注意力分配概率分布信息，区别只是在F的定义上可能有所不同。</p><p>上述内容就是经典的Soft Attention模型的基本思想，那么怎么理解Attention模型的物理含义呢？一般在自然语言处理应用里会把Attention模型看作是输出Target句子中某个单词和输入Source句子每个单词的对齐模型，这是非常有道理的。</p><p>目标句子生成的每个单词对应输入句子单词的概率分布可以理解为输入句子单词和这个目标生成单词的对齐概率，这在机器翻译语境下是非常直观的：传统的统计机器翻译一般在做的过程中会专门有一个短语对齐的步骤，而注意力模型其实起的是相同的作用。</p><h2 id="attention机制的本质思想">Attention机制的本质思想</h2><p>从图6来看待Attention机制:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205152005816.png" alt="" /><figcaption>image-20220515200505865</figcaption></figure><center><p>图6 Attention机制的本质思想</p></center><p>将Source中的构成元素想象成是由一系列的&lt;Key,Value&gt;数据对构成，此时给定Target中的某个元素Query，通过计算Query和各个Key的相似性或者相关性，得到每个Key对应Value的权重系数，然后对Value进行加权求和，即得到了最终的Attention数值。所以本质上Attention机制是对Source中元素的Value值进行加权求和，而Query和Key用来计算对应Value的权重系数。即可以将其本质思想改写为如下公式：</p><p><span class="math display">\[Attention(Query,Source)=\sum^{L_x}_{i=1}Similarity(Query,Key_i)*Value_i\]</span></p><p>其中，<span class="math inline">\(L_x\)</span>代表Source的长度，公式含义即如上所述。上文所举的机器翻译的例子里，因为在计算Attention的过程中，Source中的Key和Value合二为一，指向的是同一个东西，也即输入句子中每个单词对应的语义编码，所以可能不容易看出这种能够体现本质思想的结构。</p><p>当然，从概念上理解，把Attention仍然理解为从大量信息中有选择地筛选出少量重要信息并聚焦到这些重要信息上，忽略大多不重要的信息，这种思路仍然成立。聚焦的过程体现在权重系数的计算上，权重越大越聚焦于其对应的Value值上，即权重代表了信息的重要性，而Value是其对应的信息。</p><p>至于Attention机制的具体计算过程，如果对目前大多数方法进行抽象的话，可以将其归纳为两个过程</p><ol type="1"><li>阶段一: 根据Query和Key计算权重系数<ol type="1"><li>根据Query和Key计算两者的相似性或者相关性</li><li>对1的原始分值进行归一化处理</li></ol></li><li>阶段二:根据权重系数对Value进行加权求和</li></ol><p>这样，可以将Attention的计算过程抽象为如图7展示的三个阶段:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205152008398.png" alt="" /><figcaption>image-20220515200858399</figcaption></figure><center><p>图7 三阶段计算Attention过程</p></center><p>在第一个阶段，可以引入不同的函数和计算机制，根据Query和某个<span class="math inline">\(Key_i\)</span>，计算两者的相似性或者相关性，最常见的方法包括：求两者的向量点积、求两者的向量Cosine相似性或者通过再引入额外的神经网络来求值，即如下方式：</p><p><span class="math display">\[\begin{align}点积:&amp;Similarity(Query,Key_i)=Query \cdot Key_i\\Cosine相似性:&amp;Similarity(Query,Key_i)=\frac{Query\cdot Key_i}{\lVert Query \rVert \cdot \lVert Key_i \rVert}\\MLP网络:&amp;Similarity(Query,Key_i)=MLP(Query,Key_i)\end{align}\]</span></p><p>第一阶段产生的分值根据具体产生的方法不同其数值取值范围也不一样，第二阶段引入类似SoftMax的计算方式对第一阶段的得分进行数值转换，一方面可以进行归一化，将原始计算分值整理成所有元素权重之和为1的概率分布；另一方面也可以通过SoftMax的内在机制更加突出重要元素的权重。即一般采用如下公式计算：</p><p><span class="math display">\[a_i=Softmax(Sim_i)=\frac{e^{Sim_i}}{\sum^{L_x}_{j=1}e^{Sim_j}}\]</span></p><p>第二阶段的计算结果<span class="math inline">\(a_i\)</span>即为对<span class="math inline">\(Value_i\)</span>应的权重系数，然后进行加权求和即可得到Attention数值：</p><p><span class="math display">\[Attention(Query,Source)=\sum^{L_x}_{i=1}a_i \cdot Value_i\]</span></p><p>通过如上三个阶段的计算，即可求出针对Query的Attention数值，目前绝大多数具体的注意力机制计算方法都符合上述的三阶段抽象计算过程。</p><h2 id="self-attention模型">Self Attention模型</h2><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161215624.png" alt="" /><figcaption>image-20220516121050914</figcaption></figure><center><p>图8 单self-attention</p></center><p>在self-attention中,输入的vector在<strong>考虑整个句子</strong>后得到向量,然后放入FC(Fully-connected)的network中,决定output. self-attention可以进行多次:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161215248.png" alt="" /><figcaption>image-20220516121550285</figcaption></figure><center><p>图9 多self-attention</p></center><p>FC:专注处理某一位置, self-attention:处理整个句子</p><p>self-attention产生中间结构为:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161228278.png" alt="" /><figcaption>image-20220516122836715</figcaption></figure><center><p>图10 根据输入得到输出</p></center><p>每一个输出都要考虑所有输入. 产生过程如下:</p><p>首先根据<span class="math inline">\(a^1\)</span>找出与<span class="math inline">\(a^1\)</span>最相关的向量:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161232161.png" alt="" /><figcaption>image-20220516123207040</figcaption></figure><p>计算方法:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161232547.png" alt="" /><figcaption>image-20220516123237616</figcaption></figure><p>将输入向量分别乘上不同的矩阵<span class="math inline">\(W^q\)</span>和<span class="math inline">\(W^k\)</span>,得到向量q,k, 这两个向量做dot-product得到相关性<span class="math inline">\(\alpha\)</span>. <strong>有很多方法得到 <span class="math inline">\(\alpha\)</span> ,这是最常用的</strong>.</p><p>之后对于<span class="math inline">\(a^1\)</span>,需要分别和<span class="math inline">\(a^2,a^3,a^4\)</span>计算<span class="math inline">\(\alpha\)</span>. 如图:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161238952.png" alt="" /><figcaption>image-20220516123846840</figcaption></figure><p>一般在实际操作中,还需要计算<span class="math inline">\(a_{1,1}\)</span>即自己和自己的关联性</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161239913.png" alt="" /><figcaption>image-20220516123926366</figcaption></figure><p>得到每一个向量的关联性后会做一个softmax.</p><p>接下来根据关联性即attention的分数抽取重要资讯:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161243926.png" alt="" /><figcaption>image-20220516124313268</figcaption></figure><p>至此根据所有sequence得到了图10中的<span class="math inline">\(b^1\)</span>.</p><p>清楚<span class="math inline">\(b^1\)</span>的计算方法后, 可以得到<span class="math inline">\(b^2,b^3,b^4\)</span>的计算方法. 这些输出不是顺序计算,而是同时计算出来的.</p><p>从矩阵的角度考虑:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161342556.png" alt="" /><figcaption>image-20220516134227237</figcaption></figure><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161346871.png" alt="" /><figcaption>image-20220516134609397</figcaption></figure><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161348267.png" alt="" /><figcaption>image-20220516134821158</figcaption></figure><p>总结而言:</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161350266.png" alt="" /><figcaption>image-20220516135016114</figcaption></figure><p>在计算中,只有<span class="math inline">\(W^q,W^k,W^v\)</span>是未知的,需要根据training data找出来</p><p>以上从I到O即为做了self-attention操作.</p><h3 id="positional-encoding">positional encoding</h3><p>但是这样处理有一定问题:<strong>no position information in self-attention</strong></p><p>解决方法:each position has a unique positional vector <span class="math inline">\(e^i\)</span></p><p>这个vector是hand-crafted 并可能learn from data</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161410451.png" alt="" /><figcaption>image-20220516141025334</figcaption></figure><h2 id="self-attention-vs-rnn">self-attention vs RNN</h2><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161419983.png" alt="" /><figcaption>image-20220516141955916</figcaption></figure><p>首先因为顺序问题,两个vector之间RNN不容易进行考虑,但是self-attention容易进行考虑. self-attention更容易抽取信息</p><p>在运算速度上,self-attention可以并行化, 速度更快</p><h2 id="multi-head-self-attention">Multi-head Self-attention</h2><p>在self-attention中用q找k计算相关性,但是相关性定义不同. 所以也许需要多个q. 不同的q负责不同的相关性.</p><figure><img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161357957.png" alt="" /><figcaption>image-20220516135747976</figcaption></figure><p>然后<img src="https://raw.githubusercontent.com/Rien190/ImgURL/master/img/202205161358892.png" alt="image-20220516135841757" /></p><p>即为本次输出</p><h1 id="reference">Reference</h1><p><a href="https://blog.csdn.net/malefactor/article/details/78767781">深度学习中的注意力机制(2017版)</a></p><p><a href="https://www.youtube.com/watch?v=hYdO9CscNes">【機器學習2021】自注意力機制 (Self-attention) (上)</a></p><p><a href="https://www.youtube.com/watch?v=gmsMY5kc-zw">【機器學習2021】自注意力機制 (Self-attention) (下)</a></p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Self-Attention</tag>
      
      <tag>NLP</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
